{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References \n",
    "- [Linear Regression From Scratch 1](https://mubaris.com/posts/linear-regression/)\n",
    "- [Linear Regression From Scratch 2](https://medium.com/we-are-orb/multivariate-linear-regression-in-python-without-scikit-learn-7091b1d45905)\n",
    "\n",
    "\n",
    "- [Calculate P-Value](https://stattrek.com/regression/slope-test.aspx)\n",
    "- [Calculate Std Err of Coef](http://faculty.cas.usf.edu/mbrannick/regression/Reg2IV.html)\n",
    "- [Calculate Std Err of Coef - 2](https://stats.stackexchange.com/questions/27916/standard-errors-for-multiple-regression-coefficients)\n",
    "\n",
    "\n",
    "- [Assumptions of Linear Regression - 1](https://www.statisticssolutions.com/assumptions-of-linear-regression/)\n",
    "- [Assumptions of Linear Regression - 2](http://r-statistics.co/Assumptions-of-Linear-Regression.html)\n",
    "- [Assumptions of Linear Regression - 3](https://www.analyticsvidhya.com/blog/2016/07/deeper-regression-analysis-assumptions-plots-solutions/)\n",
    "\n",
    "\n",
    "- [K-S test - Normality Check](https://en.wikipedia.org/wiki/Kolmogorov%E2%80%93Smirnov_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/reg_assumptions.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests for Assumptions\n",
    "\n",
    "1.  It is also important to check for outliers since linear regression is sensitive to outlier effects\n",
    "\n",
    "\n",
    "2. Linear Relationship -- Look for residual vs fitted value plots. Also, you can include polynomial terms (X, X², X³) in your model to capture the non-linear effect.\n",
    "\n",
    "\n",
    "3. Multivariate normality -  The linear regression analysis requires all variables to be multivariate normal.  This assumption can best be checked with a histogram or a Q-Q-Plot.  Normality can be checked with a goodness of fit test, e.g., the Kolmogorov-Smirnov test.  When the data is not normally distributed a non-linear transformation (e.g., log-transformation) might fix this issue.\n",
    "\n",
    "\n",
    "4. No or little multicollinearity - linear regression assumes that there is little or no multicollinearity in the data.  Multicollinearity occurs when the independent variables are too highly correlated with each other.\n",
    "\n",
    "        Multicollinearity may be tested with three central criteria:\n",
    "\n",
    "        1) Correlation matrix – when computing the matrix of Pearson’s Bivariate Correlation among all independent variables the correlation coefficients need to be smaller than 1.\n",
    "\n",
    "        2) Tolerance – the tolerance measures the influence of one independent variable on all other independent variables; the tolerance is calculated with an initial linear regression analysis.  Tolerance is defined as T = 1 – R² for these first step regression analysis.  With T < 0.1 there might be multicollinearity in the data and with T < 0.01 there certainly is.\n",
    "\n",
    "        3) Variance Inflation Factor (VIF) – the variance inflation factor of the linear regression is defined as VIF = 1/T. With VIF > 10 there is an indication that multicollinearity may be present; with VIF > 100 there is certainly multicollinearity among the variables.\n",
    "\n",
    "        4) Condition Index – the condition index is calculated using a factor analysis on the independent variables.  Values of 10-30 indicate a mediocre multicollinearity in the linear regression variables, values > 30 indicate strong multicollinearity.\n",
    "\n",
    "5. No auto-correlation - linear regression analysis requires that there is little or no autocorrelation in the data.  Autocorrelation occurs when the residuals are not independent from each other.  For instance, this typically occurs in stock prices, where the price is not independent from the previous price. n other words when the value of y(x+1) is not independent from the value of y(x).\n",
    "\n",
    "        While a scatterplot allows you to check for autocorrelations, you can test the linear regression model for autocorrelation with the Durbin-Watson test.  Durbin-Watson’s d tests the null hypothesis that the residuals are not linearly auto-correlated.  While d can assume values between 0 and 4, values around 2 indicate no autocorrelation.  As a rule of thumb values of 1.5 < d < 2.5 show that there is no auto-correlation in the data. However, the Durbin-Watson test only analyses linear autocorrelation and only between direct neighbors, which are first order effects.\n",
    "\n",
    "\n",
    "6. Homoscedasticity - The last assumption of the linear regression analysis is homoscedasticity. The scatter plot is good way to check whether the data are homoscedastic (meaning the residuals are equal across the regression line).  The following scatter plots show examples of data that are not homoscedastic (i.e., heteroscedastic):\n",
    "\n",
    "        The Goldfeld-Quandt Test can also be used to test for heteroscedasticity.  The test splits the data into two groups and tests to see if the variances of the residuals are similar across the groups.  If homoscedasticity is present, a non-linear correction might fix the problem. \n",
    "        \n",
    "        look at residual vs fitted values plot. If heteroskedasticity exists, the plot would exhibit a funnel shape pattern (shown in next section). Also, you can use Breusch-Pagan / Cook – Weisberg test or White general test to detect this phenomenon.\n",
    "        \n",
    "        To overcome heteroskedasticity, a possible way is to transform the response variable such as log(Y) or √Y. Also, you can use weighted least square method to tackle heteroskedasticity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Assumptions\n",
    "\n",
    "1. The regression model is linear in parameters\n",
    "\n",
    "\n",
    "2. The mean of residuals is zero\n",
    "\n",
    "\n",
    "3. Homoscedasticity of residuals or equal variance\n",
    "\n",
    "\n",
    "4. No autocorrelation of residuals\n",
    "\n",
    "\n",
    "5. The X variables and residuals are uncorrelated\n",
    "\n",
    "\n",
    "6. The number of observations must be greater than number of Xs\n",
    "\n",
    "\n",
    "7. The variability in X values is positive - This means the X values in a given sample must not all be the same (or even nearly the same)\n",
    "\n",
    "\n",
    "8. The regression model is correctly specified - This means that if the Y and X variable has an inverse relationship, the model equation should be specified appropriately: Y=β1+β2∗(1/X)\n",
    "\n",
    "\n",
    "9. No perfect multicollinearity\n",
    "\n",
    "\n",
    "10. Normality of residuals - The residuals should be normally distributed. If the maximum likelihood method (not OLS) is used to compute the estimates, this also implies the Y and the Xs are also normally distributed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Head</th>\n",
       "      <th>Brain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4512</td>\n",
       "      <td>1530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3738</td>\n",
       "      <td>1297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender  Age  Head  Brain\n",
       "0       1    1  4512   1530\n",
       "1       1    1  3738   1297"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"./dataset/headbrain.csv\", names= [\"Gender\", \"Age\", \"Head\", \"Brain\"], header=0)\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression using Least Sqaures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(237, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 4.64562811e+02,  2.44211749e-01, -2.39684454e+01, -2.25432537e+01])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Collecting X and Y\n",
    "num_rows = data.shape[0]\n",
    "X = data[['Head', 'Age', \"Gender\"]].values.reshape(num_rows,-1)\n",
    "print(X.shape)\n",
    "\n",
    "Y = data['Brain'].values\n",
    "\n",
    "#setting the matrixes\n",
    "ones = np.ones([X.shape[0],1])\n",
    "X = np.concatenate((ones,X),axis=1)\n",
    "\n",
    "#### WLS = inverse(XT . X) . (XT . Y)\n",
    "firstPart = np.linalg.inv(np.dot(X.T, X))\n",
    "secondPart = np.dot(X.T,Y)\n",
    "\n",
    "Wls = np.dot(firstPart, secondPart)\n",
    "Wls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Predict YHat = X . Wls\n",
    "Y_hat = np.dot(X, Wls)\n",
    "\n",
    "#### Y mean\n",
    "Y_mean = np.mean(Y)\n",
    "\n",
    "#### TSS\n",
    "TSS = np.sum(np.square(Y - Y_mean))\n",
    "\n",
    "#### RSS\n",
    "RSS = np.sum(np.square(Y - Y_hat))\n",
    "\n",
    "#### num Vars\n",
    "k = X.shape[1] - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression using Statesmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>Brain</td>      <th>  R-squared:         </th> <td>   0.653</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.648</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   146.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 19 Jan 2019</td> <th>  Prob (F-statistic):</th> <td>2.94e-53</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>08:58:38</td>     <th>  Log-Likelihood:    </th> <td> -1345.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   237</td>      <th>  AIC:               </th> <td>   2699.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   233</td>      <th>  BIC:               </th> <td>   2713.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>  464.5628</td> <td>   68.982</td> <td>    6.735</td> <td> 0.000</td> <td>  328.655</td> <td>  600.471</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Head</th>      <td>    0.2442</td> <td>    0.015</td> <td>   16.212</td> <td> 0.000</td> <td>    0.215</td> <td>    0.274</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Age</th>       <td>  -23.9684</td> <td>    9.481</td> <td>   -2.528</td> <td> 0.012</td> <td>  -42.647</td> <td>   -5.290</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Gender</th>    <td>  -22.5433</td> <td>   11.058</td> <td>   -2.039</td> <td> 0.043</td> <td>  -44.329</td> <td>   -0.757</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 7.989</td> <th>  Durbin-Watson:     </th> <td>   1.922</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.018</td> <th>  Jarque-Bera (JB):  </th> <td>   8.255</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.357</td> <th>  Prob(JB):          </th> <td>  0.0161</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.571</td> <th>  Cond. No.          </th> <td>5.48e+04</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 5.48e+04. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  Brain   R-squared:                       0.653\n",
       "Model:                            OLS   Adj. R-squared:                  0.648\n",
       "Method:                 Least Squares   F-statistic:                     146.0\n",
       "Date:                Sat, 19 Jan 2019   Prob (F-statistic):           2.94e-53\n",
       "Time:                        08:58:38   Log-Likelihood:                -1345.7\n",
       "No. Observations:                 237   AIC:                             2699.\n",
       "Df Residuals:                     233   BIC:                             2713.\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept    464.5628     68.982      6.735      0.000     328.655     600.471\n",
       "Head           0.2442      0.015     16.212      0.000       0.215       0.274\n",
       "Age          -23.9684      9.481     -2.528      0.012     -42.647      -5.290\n",
       "Gender       -22.5433     11.058     -2.039      0.043     -44.329      -0.757\n",
       "==============================================================================\n",
       "Omnibus:                        7.989   Durbin-Watson:                   1.922\n",
       "Prob(Omnibus):                  0.018   Jarque-Bera (JB):                8.255\n",
       "Skew:                           0.357   Prob(JB):                       0.0161\n",
       "Kurtosis:                       3.571   Cond. No.                     5.48e+04\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 5.48e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formula = \"Brain ~ Head + Age + Gender\"\n",
    "model = smf.OLS.from_formula(formula, data)\n",
    "\n",
    "result = model.fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Y  X1  X2\n",
       "0  1  40  25\n",
       "1  2  45  20"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"./dataset/lin_reg_test.csv\")\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression using Least Sqaures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-4.10358123,  0.08640901,  0.08760164])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Collecting X and Y\n",
    "num_rows = data.shape[0]\n",
    "X = data[['X1', 'X2']].values.reshape(num_rows,-1)\n",
    "print(X.shape)\n",
    "\n",
    "Y = data['Y'].values\n",
    "\n",
    "#setting the matrixes\n",
    "ones = np.ones([X.shape[0],1])\n",
    "X = np.concatenate((ones,X),axis=1)\n",
    "\n",
    "#### WLS = inverse(XT . X) . (XT . Y)\n",
    "firstPart = np.linalg.inv(np.dot(X.T, X))\n",
    "secondPart = np.dot(X.T,Y)\n",
    "\n",
    "Wls = np.dot(firstPart, secondPart)\n",
    "Wls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Predict YHat = X . Wls\n",
    "Y_hat = np.dot(X, Wls)\n",
    "\n",
    "#### Y mean\n",
    "Y_mean = np.mean(Y)\n",
    "\n",
    "#### TSS\n",
    "TSS = np.sum(np.square(Y - Y_mean))\n",
    "\n",
    "#### RSS\n",
    "RSS = np.sum(np.square(Y - Y_hat))\n",
    "\n",
    "#### Residual Variance\n",
    "res_var = np.var(Y - Y_hat)\n",
    "\n",
    "#### num Vars\n",
    "k = X.shape[1] - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression using Statesmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>Y</td>        <th>  R-squared:         </th> <td>   0.671</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.632</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   17.33</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 19 Jan 2019</td> <th>  Prob (F-statistic):</th> <td>7.89e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:59:20</td>     <th>  Log-Likelihood:    </th> <td> -21.235</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    20</td>      <th>  AIC:               </th> <td>   48.47</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    17</td>      <th>  BIC:               </th> <td>   51.46</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   -4.1036</td> <td>    1.261</td> <td>   -3.254</td> <td> 0.005</td> <td>   -6.764</td> <td>   -1.443</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X1</th>        <td>    0.0864</td> <td>    0.031</td> <td>    2.748</td> <td> 0.014</td> <td>    0.020</td> <td>    0.153</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X2</th>        <td>    0.0876</td> <td>    0.045</td> <td>    1.926</td> <td> 0.071</td> <td>   -0.008</td> <td>    0.184</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 4.288</td> <th>  Durbin-Watson:     </th> <td>   1.933</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.117</td> <th>  Jarque-Bera (JB):  </th> <td>   2.697</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.890</td> <th>  Prob(JB):          </th> <td>   0.260</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.255</td> <th>  Cond. No.          </th> <td>    460.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      Y   R-squared:                       0.671\n",
       "Model:                            OLS   Adj. R-squared:                  0.632\n",
       "Method:                 Least Squares   F-statistic:                     17.33\n",
       "Date:                Sat, 19 Jan 2019   Prob (F-statistic):           7.89e-05\n",
       "Time:                        10:59:20   Log-Likelihood:                -21.235\n",
       "No. Observations:                  20   AIC:                             48.47\n",
       "Df Residuals:                      17   BIC:                             51.46\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     -4.1036      1.261     -3.254      0.005      -6.764      -1.443\n",
       "X1             0.0864      0.031      2.748      0.014       0.020       0.153\n",
       "X2             0.0876      0.045      1.926      0.071      -0.008       0.184\n",
       "==============================================================================\n",
       "Omnibus:                        4.288   Durbin-Watson:                   1.933\n",
       "Prob(Omnibus):                  0.117   Jarque-Bera (JB):                2.697\n",
       "Skew:                          -0.890   Prob(JB):                        0.260\n",
       "Kurtosis:                       3.255   Cond. No.                         460.\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formula = \"Y ~ X1 + X2\"\n",
    "model = smf.OLS.from_formula(formula, data)\n",
    "\n",
    "result = model.fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### R-Sqaured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R_squared:  0.6709278876377617\n"
     ]
    }
   ],
   "source": [
    "R_squared = 1 - (RSS/TSS)\n",
    "print(\"R_squared: \", R_squared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adj. R-Sqaured\n",
    "\n",
    "<img src=\"./images/adj_r.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adj_R_squared:  0.6322135214774983\n"
     ]
    }
   ],
   "source": [
    "numerator = (1-R_squared) * (num_rows-1)\n",
    "denominator = num_rows - k - 1\n",
    "adj_R_squared = 1 - numerator/denominator\n",
    "print(\"adj_R_squared: \", adj_R_squared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing the Significance of R2\n",
    "\n",
    "<img src=\"./images/f_value.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F Value:  17.330204628957773\n"
     ]
    }
   ],
   "source": [
    "numerator = R_squared/k\n",
    "denominator = (1- R_squared)/(num_rows - k -1)\n",
    "\n",
    "F = numerator/denominator\n",
    "\n",
    "print(\"F Value: \", F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation\n",
    "\n",
    "<img src=\"./images/corr.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "correlation between  Y and X1 is :  0.7740324668726798\n",
      "\n",
      "correlation between  Y and X2 is :  0.7243900839094041\n",
      "\n",
      "correlation between  X1 and X2 is :  0.6830081654612543\n"
     ]
    }
   ],
   "source": [
    "corr_dict = {}\n",
    "all_pairs = list(combinations(data.columns,2))\n",
    "for pair in all_pairs:\n",
    "    print()\n",
    "    col_1 = pair[0]\n",
    "    col_2 = pair[1]\n",
    "    numerator = np.sum((data[col_1] - np.mean(data[col_1])) * (data[col_2] - np.mean(data[col_2])))\n",
    "    denominator = np.sqrt(np.sum(np.square((data[col_1] - np.mean(data[col_1])))) * \n",
    "                          np.sum(np.square((data[col_2] - np.mean(data[col_2])))))\n",
    "    corr = numerator/denominator\n",
    "    print(\"correlation between \", col_1, \"and\", col_2, \"is : \", corr)\n",
    "    corr_dict[col_1 + \"_\" + col_2] = round(corr,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Y_X1': 0.774, 'Y_X2': 0.724, 'X1_X2': 0.683}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests of Regression Coefficients\n",
    "\n",
    "\n",
    "<img src=\"./images/reg_coef1.jpg\">\n",
    "<img src=\"./images/reg_coef2.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SE:  0.5758761966339171\n"
     ]
    }
   ],
   "source": [
    "#### SE = S_quared_y_12\n",
    "SE = RSS/(num_rows - k - 1)\n",
    "print(\"SE: \", SE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SE_X1:  0.03144280843430527\n"
     ]
    }
   ],
   "source": [
    "#### SE for X1\n",
    "numerator = SE\n",
    "variance = np.sum(np.square((data[\"X1\"] - np.mean(data[\"X1\"]))))\n",
    "denominator = variance * (1 - np.square(corr_dict[\"X1_X2\"]))\n",
    "\n",
    "SE_X1 = np.sqrt(numerator/denominator)\n",
    "print(\"SE_X1: \", SE_X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SE_X2:  0.04548431367217167\n"
     ]
    }
   ],
   "source": [
    "#### SE for X2\n",
    "numerator = SE\n",
    "variance = np.sum(np.square((data[\"X2\"] - np.mean(data[\"X2\"]))))\n",
    "denominator = variance * (1 - np.square(corr_dict[\"X1_X2\"]))\n",
    "\n",
    "SE_X2 = np.sqrt(numerator/denominator)\n",
    "print(\"SE_X2: \", SE_X2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T-Value\n",
    "\n",
    "<img src=\"./images/t_value.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t_X1:  2.7481325777418877\n"
     ]
    }
   ],
   "source": [
    "#### t value for X1\n",
    "t_X1 = Wls[1]/ SE_X1\n",
    "print(\"t_X1: \", t_X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t_X2:  1.925974826593649\n"
     ]
    }
   ],
   "source": [
    "#### t value for X2\n",
    "t_X2 = Wls[2]/ SE_X2\n",
    "print(\"t_X2: \", t_X2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### P-Value\n",
    "\n",
    "- A P-value measures the strength of evidence in support of a null hypothesis. Suppose the test statistic in a hypothesis test is equal to S. The P-value is the probability of observing a test statistic as extreme as S, assuming the null hypotheis is true. If the P-value is less than the significance level, we reject the null hypothesis.\n",
    "\n",
    "<img src=\"./images/hypothesis.jpg\">\n",
    "\n",
    "- Reject Null Hypothesis if P < 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two tails - p Value:  0.014\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "#Degrees of freedom\n",
    "df = num_rows - k - 1\n",
    "\n",
    "#p-value after comparison with the t \n",
    "p = 1 - stats.t.cdf(t_X1,df=df)\n",
    "print(\"Two tails - p Value: \", round(p*2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two tails - p Value:  0.071\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "#Degrees of freedom\n",
    "df = num_rows - k - 1\n",
    "\n",
    "#p-value after comparison with the t \n",
    "p = 1 - stats.t.cdf(t_X2,df=df)\n",
    "print(\"Two tails - p Value: \", round(p*2, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AIC\n",
    "\n",
    "<img src=\"./images/AIC.jpg\">\n",
    "\n",
    "<img src=\"./images/AIC1.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIC:  48.47\n"
     ]
    }
   ],
   "source": [
    "#### as per wikipedia formula\n",
    "AIC = 2 * (k+1) + num_rows * (np.log(2 * (np.pi) * RSS/num_rows ) + 1)\n",
    "print(\"AIC: \", round(AIC, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BIC\n",
    "\n",
    "<img src=\"./images/BIC.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BIC:  51.46\n"
     ]
    }
   ],
   "source": [
    "#### BIC\n",
    "BIC = np.log(num_rows) * (k) + num_rows * (np.log(2 * (np.pi) * RSS/num_rows ) + 1)\n",
    "print(\"BIC: \", round(BIC, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DW\n",
    "\n",
    "<img src=\"./images/DW.jpg\">\n",
    "\n",
    "In statistics, the Durbin–Watson statistic is a test statistic used to detect the presence of autocorrelation at lag 1 in the residuals (prediction errors) from a regression analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9333065303576837"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Residual\n",
    "res = Y - Y_hat\n",
    "\n",
    "#### Residual (index + 1)\n",
    "res_plus_1 = res[1:]\n",
    "\n",
    "#### Numerator\n",
    "numerator = np.sum(np.square((res_plus_1 - res[:-1])))\n",
    "\n",
    "#### Denominator\n",
    "denominator = RSS\n",
    "\n",
    "DW = numerator/denominator\n",
    "DW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CP\n",
    "\n",
    "<img src=\"./images/cp.jpg\">\n",
    "\n",
    "- In statistics, Mallows’s Cp, named for Colin Lingwood Mallows, is used to assess the fit of a regression model that has been estimated using ordinary least squares. It is applied in the context of model selection, where a number of predictor variables are available for predicting some outcome, and the goal is to find the best model involving a subset of these predictors. A small value of Cp means that the model is relatively precise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6363431972804785"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CP = (1/num_rows) * (RSS + 2 * k * np.var(Y-Y_hat))\n",
    "CP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-S test - to Check Multivariate normality\n",
    "\n",
    "<img src=\"./images/ks.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VIF - to Check multicollinearity\n",
    "\n",
    "<img src=\"./images/vif1.jpg\">\n",
    "<img src=\"./images/vif2.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"./images/cook1.jpg\">\n",
    "<img src=\"./images/cook2.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflowcpu]",
   "language": "python",
   "name": "conda-env-tensorflowcpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
