{"cells":[{"metadata":{"_uuid":"3cc883fe4e92474c5073cd040b7ea3ffb498d4d6"},"cell_type":"markdown","source":"# INDEX\n## as per baseline\n1. merge train and test\n2. do some shit to understand data\n3. *missing* >> engineer features on df\n## other approach\n4. group and median in train2\n5. model building >> **doesn't run, problem with input shapes**\n## build 'main' model\n6. split df in train and test (now nonesense as no features are present)\n7. build model\n8. train and test","outputs":[],"execution_count":null},{"metadata":{"_uuid":"2dd220c62c14fc79707e2401e1223a0306f01418"},"cell_type":"markdown","source":"# TODO:\n* imports and loading data\n* remove NaN\n* check out data\n* look for correlations\n    * scatterplots between all vars and y\n* make dummy variables for categorical data\n    * store type\n    * [...]\n* highlight relationship between sales and holidays\n* make model\n    * test different:\n        * number of nodes\n        * activation functions","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"44ed44d4-5022-4868-9e70-161052700aa3","_uuid":"c76cb8c8316dd68d9ffaa8237928f39b765ae71b","collapsed":true},"cell_type":"markdown","source":"## Importing - setup - load data","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"1d3306bb-0b2e-47b0-a0c4-cc95c9cad3d9","_uuid":"1bcbfb6771c42872cc36896ddb9ea92fa405b0d7","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.optimizers import SGD\n\n# Set seed for reproducability \nnp.random.seed(42)\n\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"5ab2bdd1-bdf7-4e47-b218-7c37777519ad","_uuid":"545727d68cbf7cd30b25b6c9cd6f97c2c1745b28","collapsed":true},"cell_type":"markdown","source":"concatenate data into pandas dataframe in order to pre-process data and create dummy vars.","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"10ca5b69-25f6-4ae5-ab45-4f5fac0d08c4","_uuid":"23a2b687521c6b56e51c9d86d3268b500d4ffcfa","scrolled":true,"trusted":true},"cell_type":"code","source":"df = pd.concat([train,test],axis=0)\ndf.head(20)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"0ea2e2ca-ae60-4efa-92f4-5740f03b965c","_uuid":"0cb94f25239a99ebf2c0e7cd175864f463957b9a","trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b3f4e9cf-5e3c-48c3-923f-a1bf6e4579ac","_uuid":"1d7b11f8ac9931d11eefa7705943cd722c3bce03"},"cell_type":"markdown","source":"## fix missing values\nnow we fill in the missing values with 0, as they are all those referring to markdowns.\nthe process applies to \n* markdown columns\n* weekly sale of test data, which can be safely set to zero as we will predict those value later on","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"f594dae7-9fde-431c-bd2f-50f5568ba8a6","_uuid":"129a92baacbf0f838b7faaa94565876cfda80f5e","trusted":true},"cell_type":"code","source":"df.fillna(0, inplace=True)\ndf.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"e80fa209-5a49-438a-ae23-20c190916374","_uuid":"1c18c4945d0704232e933f9391ff5ec594240c5f","trusted":true},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"83ba7718-9a0d-4f05-92a9-b3ec77bc0bc8","_uuid":"81dded851e8947e01f0a518f7f1336f24dad3d3d"},"cell_type":"markdown","source":"next step is to prep the data (converting in to dummies) like in the example from [here](https://www.kaggle.com/erkkinool/bletchley-week-2-walmart-sales-forecast) and try to run a first model. after the baseline I'll try to get better performance.","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"9c438aa9-2f31-4ffb-8440-8551a291269b","_uuid":"ea03cbbf85ae229c0f3525d456136af46bf28fe1","trusted":true},"cell_type":"code","source":"df.head(10)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"6bfcef71-501a-4d2c-b3c1-72aced26f4f6","_uuid":"ba1ce2b5ca948a7159b60d097fbed1bcd92d0785"},"cell_type":"markdown","source":"# looking for correlations\nto build some features i look for some correlation btween vars and sales. scatterplots are an easy solution.","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"356f03f1-137d-488e-90c9-97030e853297","_uuid":"cee08f392d70270ce0bc85fd54aad4402b941c5d","trusted":true},"cell_type":"code","source":"def scatterplots(feature, label):\n    x = feature\n    y = df['Weekly_Sales']\n    plt.scatter(x, y)\n    plt.ylabel('sales')\n    plt.xlabel(label)\n    plt.show()\n    \nfig = plt.gcf()\nfig.set_size_inches(8, 8)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"c3c6c675-74ee-454b-bd73-33d337f297d6","_uuid":"ee1bfdcd94d98f30135dd6238a43c5c2f57644a5","trusted":true,"scrolled":true},"cell_type":"code","source":"headers = list(df)\nlabels = headers\nscatterplots(df['CPI'], 'CPI')\nscatterplots(df['Date'], 'Date') # date isn't readable in scatterplot. make it timeseries\nscatterplots(df['Dept'], 'Dept')\nscatterplots(df['Fuel_Price'], 'Fuel_Price')\nscatterplots(df['IsHoliday'], 'IsHoliday')\nscatterplots(df['MarkDown1'], 'MarkDown1')\nscatterplots(df['MarkDown2'], 'MarkDown2')\nscatterplots(df['MarkDown3'], 'MarkDown3')\nscatterplots(df['MarkDown4'], 'MarkDown4')\nscatterplots(df['MarkDown5'], 'MarkDown5')\nscatterplots(df['Size'], 'Size')\nscatterplots(df['Store'], 'Store')\nscatterplots(df['Temperature'], 'Temperature')\nscatterplots(df['Type'], 'Type')\nscatterplots(df['Unemployment'], 'Unemployment')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6df75559fb0d88ce0a75cc15f47e64117b4b9e3e"},"cell_type":"markdown","source":"### comment: \nthe scatterplot approach worked halfway. some cool relationships there but would be worth to investigate further. Some observations:\n* high correlation between holiday and sales. some outliers. don't think there is additional feature to be made of that.\n* two big spikes around ?christmas? in sales. >> **make feature of that**, maybe for whole month. no need for every week\n* relation between CPI. first block has more variability.... don't understand the sense of it\n* high correlation between some dpt and sales. >> **make conditional hystogram like in example to investigate further**\n* at some levels of fuel we have more variability. mmm...\n* negative correlation btween markdown and sales?\n* temperature can be split in three blocks. >> **make feature of it** medium temp is favorable for sales\n* type B sells nmore than others. no feature there i think\n* unemployment doesn't look interesting. maybe rising or dropping unemployment? there is probably some delay there though.\n\n","outputs":[],"execution_count":null},{"metadata":{"_uuid":"9b023694a8b3a78c8a9498567af63e0217f76f56"},"cell_type":"markdown","source":"### TODO further research:\n* sum of sales by year. could be a trend there. correlate sales trend with macro variables. macro variables are unlikely to be strongly correlated with weekly stuff, or maybe it's implicitly in the model?\n* check out:\n    * https://www.kaggle.com/c/walmart-recruiting-store-sales-forecasting/discussion/8033\n    * https://www.kaggle.com/c/walmart-recruiting-store-sales-forecasting/discussion/8023\n    * good simple model https://www.kaggle.com/c/see-click-predict-fix/discussion/6466#35490","outputs":[],"execution_count":null},{"metadata":{"_uuid":"0f4885d2f684c8d191fffb1598337a9f8e991507"},"cell_type":"markdown","source":"# Simple model approach as per [here](https://www.kaggle.com/c/see-click-predict-fix/discussion/6466#35490)","outputs":[],"execution_count":null},{"metadata":{"_uuid":"f63e2488652528fae143ab802f83bff4bdbabe0d"},"cell_type":"markdown","source":"creating month column. \nI have done it both on df and on new dataframe 'train2' which is just modified \"train\"","outputs":[],"execution_count":null},{"metadata":{"trusted":true,"_uuid":"979c8adbd27d241275a9e5c016a1fb81b696aba7"},"cell_type":"code","source":"# extract month from date\ndf['month'] = pd.DatetimeIndex(df['Date']).month","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eb92052d88b3458eeac698990fdf357cb51a05a8"},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"2091e13a730392a9481990af0fc1c4aeb76c9254"},"cell_type":"code","source":"# create train2. take median and groupby. get mean_vals\ntrain2 = train\ntrain2['month'] = pd.DatetimeIndex(train2['Date']).month\nmean_vals = train2.groupby(['Store', 'Dept', 'month', 'IsHoliday']).median()\n# replace NaN\nmean_vals.fillna(0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"80c9c0c500d46fdd2a237eb0af7b3a8ecf1a24a0"},"cell_type":"code","source":"mean_vals.dtypes","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fdb606991733fd0ca1c55a38f1f3922c2a9f372c"},"cell_type":"markdown","source":"now let's try to run a **model** on it","outputs":[],"execution_count":null},{"metadata":{"trusted":true,"_uuid":"e537673f4860f7fe8bc5c5cbf4b4e2d3105766e8"},"cell_type":"code","source":"y1 = train2['Weekly_Sales'].values\nX1 = train2.drop('Weekly_Sales',axis=1).values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3e7253eba6e87293fc3ca9e0b2a14f561398e874"},"cell_type":"code","source":"model = Sequential()\n\n# std 3 layer network\nmodel.add(Dense(units=320, input_dim=16, activation='tanh'))\nmodel.add(Dense(units=160, activation='tanh'))\nmodel.add(Dense(units=10, activation='softmax'))\n\nmodel.compile(optimizer='adam',\n              loss='mae',\n              metrics=['acc'])\n\nmodel.fit(X1, y1, epochs=10, batch_size= 2048)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"ac4b39328411b8a8e14a9088516e9e851ce14404"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0bea36baec43af66182c994c1dfa195b621f2b40"},"cell_type":"markdown","source":"# build a model\n","outputs":[],"execution_count":null}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}