{"cells":[{"metadata":{"_cell_guid":"8857c7ce-afc2-4ac6-bcb5-017ff3a0bd2e","_kg_hide-input":true,"_uuid":"585b93d54f567edd035b466a866b87834f7adc67","collapsed":true,"trusted":true},"cell_type":"code","source":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\n\nlen(train) # Get number of training examples\n\nlen(test) # Get number of test examples\n\ndf = pd.concat([train,test],axis=0) # Join train and test\ndf.head() # Get an overview of the data\n\n#df.isnull().sum()\n\ndf.fillna(0, inplace=True)\n\ndf['Week'] = pd.to_datetime(df.Date).dt.week\n\n# Make sure we can later recognize what a dummy once belonged to\ndf['Type'] = 'Type_' + df['Type'].map(str)\ndf['Store'] = 'Store_' + df['Store'].map(str)\ndf['Dept'] = 'Dept_' + df['Dept'].map(str)\ndf['Week'] = 'Week_' + df['Week'].map(str)\n\n# Create dummies\ntype_dummies = pd.get_dummies(df['Type'])\nstore_dummies = pd.get_dummies(df['Store'])\ndept_dummies = pd.get_dummies(df['Dept'])\nweek_dummies = pd.get_dummies(df['Week'])\n\n# Add dummies\ndf = pd.concat([df,type_dummies,store_dummies,dept_dummies, week_dummies],axis=1)\n\n# Remove originals\ndel df['Type']\ndel df['Store']\ndel df['Dept']\ndel df['Week']\ndel df['Date']\n\n# Remove variables that are not useful\ndel df['CPI']\ndel df['MarkDown2']\ndel df['MarkDown3']\ndel df['MarkDown4']\ndel df['MarkDown5']\ndel df['Unemployment']\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"46cf761b-b809-4e9c-8410-221353fcedc8","_uuid":"8edf4bdd14f24f20313e26f78c24a21bc63fee12","trusted":true},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"576a69da-01b6-460d-9b0c-437b119570c0","_uuid":"63c9a3fff261775af83a2df1a30db8c25fd25238","collapsed":true,"trusted":true},"cell_type":"code","source":"#Split the sets\n#train = df.iloc[:282451]\n#test = df.iloc[282451:]\n\n# smaller training set just to test out different models\n#train_fake = df.iloc[:15000]\ntrain = df.iloc[:282451]\n\n#test_fake = df.iloc[15000:20000]\ntest = df.iloc[282451:]\n\n#test = test.drop('Weekly_Sales',axis=1) # We should remove the nonsense values from test\ntest = test.drop('Weekly_Sales',axis=1) # We should remove the nonsense values from test\n\n\n#numpy array out of the panda data frame FOR FAKES\ny = train['Weekly_Sales'].values\nX = train.drop('Weekly_Sales',axis=1).values\n\n#numpy array out of the panda data frame\n#y = train['Weekly_Sales'].values\n#X = train.drop('Weekly_Sales',axis=1).values","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"eee815a3-dd16-4090-b759-6aa3f0cf8b36","_uuid":"4a90cf27adb89a8bf28722bbb2beea5b518ca084","trusted":true},"cell_type":"code","source":"X.shape","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"c6500fff-5547-4756-a53a-d424c7d22b0b","_uuid":"7e4da53da14e64e5c48ffd679ddf82a5a3560619","trusted":true},"cell_type":"code","source":"from keras.layers import Dense, Activation\nfrom keras.models import Sequential\nfrom keras import metrics\nfrom keras import regularizers\nfrom keras.layers import Dropout\nfrom keras.layers import BatchNormalization\nfrom keras.layers import Activation\nfrom keras.optimizers import adam\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"910241cd-9c3f-4bd5-b1f0-2cd58ee677f6","_uuid":"5b129c8c1c50cb0bb0de6ba15646e921711d3053","collapsed":true,"trusted":true},"cell_type":"code","source":"# Sequential model\nmodel = Sequential()\n\n# Logistic regresison is a single layer network\nmodel.add(Dense(50,activation='relu',input_dim=186))\n\nmodel.add(Dense(50,activation='relu'))\n\nmodel.add(Dense(50,activation='relu'))\n\nmodel.add(Dense(1,activation='linear'))\n\n# Compile the model\nmodel.compile(optimizer='adam',loss='mae',metrics=['mae'])\n\n#model.fit(X, y, # Train on training set\n                            # epochs=1000, # We will train over 1,000 epochs\n                            # batch_size=X.shape[0], # Batch size = training set size\n                            # verbose=0) # Suppress Keras output\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d1ef7cb1153432544053fcae5fbc9047ed9f336e"},"cell_type":"code","source":"# Train\nhistory = model.fit(X, y, epochs=5, batch_size = 100) ","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"8a3e3305-a6f3-43eb-94bb-f89860a7480b","_uuid":"f2c13a261055e9f5dc0f740919bd5123150dd53d","collapsed":true,"trusted":true},"cell_type":"code","source":"plt.plot(history.history['mean_absolute_error'])\nplt.xlabel('Epochs')\nplt.ylabel('mae')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8794f797b2801b37c2c9e53e1227b8afc46bcd95"},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"228ee1062d1bc589bbc33642a38618101ecfec03"},"cell_type":"code","source":"ypred = model.predict(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"5fc581a1d4ae2d3dab2df31620727f0f7ed54ee0"},"cell_type":"code","source":"testfile = pd.read_csv('../input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"b4f1162a4e9dab84aab5a34c61f6812b0da8fbdf"},"cell_type":"code","source":"submission = pd.DataFrame({'id':testfile['Store'].map(str) + '_' + testfile['Dept'].map(str) + '_' + testfile['Date'].map(str),\n                          'Weekly_Sales':ypred.flatten()})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"a2722326917d635b42d555919ead78ffff4f5092"},"cell_type":"code","source":"submission.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}