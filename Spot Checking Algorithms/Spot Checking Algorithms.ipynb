{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "- https://machinelearningmastery.com/spot-check-machine-learning-algorithms-in-python/\n",
    "- https://machinelearningmastery.com/spot-check-classification-machine-learning-algorithms-python-scikit-learn/\n",
    "- https://machinelearningmastery.com/why-you-should-be-spot-checking-algorithms-on-your-machine-learning-problems/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\DS_Softwares\\anaconda3\\envs\\tensorflowcpu\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 53 models\n",
      ">logistic: 0.846 (+/-0.039)\n",
      ">ridge-0.1: 0.847 (+/-0.037)\n",
      ">ridge-0.2: 0.847 (+/-0.037)\n",
      ">ridge-0.3: 0.847 (+/-0.037)\n",
      ">ridge-0.4: 0.848 (+/-0.038)\n",
      ">ridge-0.5: 0.848 (+/-0.038)\n",
      ">ridge-0.6: 0.848 (+/-0.038)\n",
      ">ridge-0.7: 0.848 (+/-0.038)\n",
      ">ridge-0.8: 0.848 (+/-0.038)\n",
      ">ridge-0.9: 0.848 (+/-0.038)\n",
      ">ridge-1.0: 0.847 (+/-0.038)\n",
      ">sgd: 0.773 (+/-0.081)\n",
      ">pa: 0.792 (+/-0.043)\n",
      ">knn-1: 0.726 (+/-0.042)\n",
      ">knn-2: 0.688 (+/-0.030)\n",
      ">knn-3: 0.740 (+/-0.038)\n",
      ">knn-4: 0.727 (+/-0.027)\n",
      ">knn-5: 0.767 (+/-0.036)\n",
      ">knn-6: 0.757 (+/-0.026)\n",
      ">knn-7: 0.769 (+/-0.037)\n",
      ">knn-8: 0.762 (+/-0.044)\n",
      ">knn-9: 0.773 (+/-0.044)\n",
      ">knn-10: 0.767 (+/-0.042)\n",
      ">knn-11: 0.783 (+/-0.041)\n",
      ">knn-12: 0.781 (+/-0.045)\n",
      ">knn-13: 0.789 (+/-0.041)\n",
      ">knn-14: 0.787 (+/-0.038)\n",
      ">knn-15: 0.799 (+/-0.044)\n",
      ">knn-16: 0.791 (+/-0.039)\n",
      ">knn-17: 0.799 (+/-0.027)\n",
      ">knn-18: 0.797 (+/-0.030)\n",
      ">knn-19: 0.801 (+/-0.031)\n",
      ">knn-20: 0.802 (+/-0.034)\n",
      ">cart: 0.806 (+/-0.038)\n",
      ">extra: 0.711 (+/-0.050)\n",
      ">svml: 0.843 (+/-0.035)\n",
      ">svmp: 0.773 (+/-0.034)\n",
      ">svmr0.1: 0.797 (+/-0.034)\n",
      ">svmr0.2: 0.781 (+/-0.043)\n",
      ">svmr0.3: 0.805 (+/-0.032)\n",
      ">svmr0.4: 0.817 (+/-0.032)\n",
      ">svmr0.5: 0.823 (+/-0.029)\n",
      ">svmr0.6: 0.828 (+/-0.031)\n",
      ">svmr0.7: 0.833 (+/-0.030)\n",
      ">svmr0.8: 0.838 (+/-0.033)\n",
      ">svmr0.9: 0.838 (+/-0.034)\n",
      ">svmr1.0: 0.837 (+/-0.032)\n",
      ">bayes: 0.816 (+/-0.034)\n",
      ">ada: 0.850 (+/-0.035)\n",
      ">bag: 0.864 (+/-0.041)\n",
      ">rf: 0.864 (+/-0.034)\n",
      ">et: 0.864 (+/-0.033)\n",
      ">gbm: 0.866 (+/-0.044)\n",
      "\n",
      "Rank=1, Name=gbm, Score=0.866 (+/- 0.044)\n",
      "Rank=2, Name=bag, Score=0.864 (+/- 0.041)\n",
      "Rank=3, Name=rf, Score=0.864 (+/- 0.034)\n",
      "Rank=4, Name=et, Score=0.864 (+/- 0.033)\n",
      "Rank=5, Name=ada, Score=0.850 (+/- 0.035)\n",
      "Rank=6, Name=ridge-0.9, Score=0.848 (+/- 0.038)\n",
      "Rank=7, Name=ridge-0.8, Score=0.848 (+/- 0.038)\n",
      "Rank=8, Name=ridge-0.7, Score=0.848 (+/- 0.038)\n",
      "Rank=9, Name=ridge-0.6, Score=0.848 (+/- 0.038)\n",
      "Rank=10, Name=ridge-0.5, Score=0.848 (+/- 0.038)\n"
     ]
    }
   ],
   "source": [
    "# binary classification spot check script\n",
    "import warnings\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from matplotlib import pyplot\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "##############################################################\n",
    "##############################################################\n",
    "\n",
    "# load the dataset, returns X and y elements\n",
    "def load_dataset():\n",
    "    return make_classification(n_samples=1000, n_classes=2, random_state=1)\n",
    "\n",
    "##############################################################\n",
    "##############################################################\n",
    "\n",
    "# create a dict of standard models to evaluate {name:object}\n",
    "def define_models(models=dict()):\n",
    "    \n",
    "    ####################################\n",
    "    \n",
    "    # linear models\n",
    "    models['logistic'] = LogisticRegression()\n",
    "    \n",
    "    alpha = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "    for a in alpha:\n",
    "        models['ridge-'+str(a)] = RidgeClassifier(alpha=a)\n",
    "        \n",
    "    models['sgd'] = SGDClassifier(max_iter=1000, tol=1e-3)\n",
    "    models['pa'] = PassiveAggressiveClassifier(max_iter=1000, tol=1e-3)\n",
    "    \n",
    "    ####################################\n",
    "    \n",
    "    # non-linear models\n",
    "    \n",
    "    n_neighbors = range(1, 21)\n",
    "    for k in n_neighbors:\n",
    "        models['knn-'+str(k)] = KNeighborsClassifier(n_neighbors=k)\n",
    "        \n",
    "    models['cart'] = DecisionTreeClassifier()\n",
    "    models['extra'] = ExtraTreeClassifier()\n",
    "    models['svml'] = SVC(kernel='linear')\n",
    "    models['svmp'] = SVC(kernel='poly')\n",
    "    \n",
    "    c_values = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "    for c in c_values:\n",
    "        models['svmr'+str(c)] = SVC(C=c)\n",
    "        \n",
    "    models['bayes'] = GaussianNB()\n",
    "    \n",
    "    ####################################\n",
    "    \n",
    "    # ensemble models\n",
    "    n_trees = 100\n",
    "    models['ada'] = AdaBoostClassifier(n_estimators=n_trees)\n",
    "    models['bag'] = BaggingClassifier(n_estimators=n_trees)\n",
    "    models['rf'] = RandomForestClassifier(n_estimators=n_trees)\n",
    "    models['et'] = ExtraTreesClassifier(n_estimators=n_trees)\n",
    "    models['gbm'] = GradientBoostingClassifier(n_estimators=n_trees)\n",
    "    \n",
    "    ####################################\n",
    "    \n",
    "    print('Defined %d models' % len(models))\n",
    "    return models\n",
    "\n",
    "##############################################################\n",
    "##############################################################\n",
    "\n",
    "# create a feature preparation pipeline for a model\n",
    "def make_pipeline(model):\n",
    "    steps = list()\n",
    "    # standardization\n",
    "    steps.append(('standardize', StandardScaler()))\n",
    "    # normalization\n",
    "    steps.append(('normalize', MinMaxScaler()))\n",
    "    # the model\n",
    "    steps.append(('model', model))\n",
    "    # create pipeline\n",
    "    pipeline = Pipeline(steps=steps)\n",
    "    return pipeline\n",
    "\n",
    "##############################################################\n",
    "##############################################################\n",
    "\n",
    "# evaluate a single model\n",
    "def evaluate_model(X, y, model, folds, metric):\n",
    "    # create the pipeline\n",
    "    pipeline = make_pipeline(model)\n",
    "    # evaluate model\n",
    "    scores = cross_val_score(pipeline, X, y, scoring=metric, cv=folds, n_jobs=-1)\n",
    "    return scores\n",
    "\n",
    "##############################################################\n",
    "##############################################################\n",
    "\n",
    "# evaluate a model and try to trap errors and and hide warnings\n",
    "def robust_evaluate_model(X, y, model, folds, metric):\n",
    "    scores = None\n",
    "    try:\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings(\"ignore\")\n",
    "            scores = evaluate_model(X, y, model, folds, metric)\n",
    "    except:\n",
    "        scores = None\n",
    "    return scores\n",
    "\n",
    "##############################################################\n",
    "##############################################################\n",
    "\n",
    "# evaluate a dict of models {name:object}, returns {name:score}\n",
    "def evaluate_models(X, y, models, folds=10, metric='accuracy'):\n",
    "    results = dict()\n",
    "    for name, model in models.items():\n",
    "        # evaluate the model\n",
    "        scores = robust_evaluate_model(X, y, model, folds, metric)\n",
    "        # show process\n",
    "        if scores is not None:\n",
    "            # store a result\n",
    "            results[name] = scores\n",
    "            mean_score, std_score = mean(scores), std(scores)\n",
    "            print('>%s: %.3f (+/-%.3f)' % (name, mean_score, std_score))\n",
    "        else:\n",
    "            print('>%s: error' % name)\n",
    "    return results\n",
    "\n",
    "##############################################################\n",
    "##############################################################\n",
    "\n",
    "# print and plot the top n results\n",
    "def summarize_results(results, maximize=True, top_n=10):\n",
    "    # check for no results\n",
    "    if len(results) == 0:\n",
    "        print('no results')\n",
    "        return\n",
    "    # determine how many results to summarize\n",
    "    n = min(top_n, len(results))\n",
    "    # create a list of (name, mean(scores)) tuples\n",
    "    mean_scores = [(k,mean(v)) for k,v in results.items()]\n",
    "    # sort tuples by mean score\n",
    "    mean_scores = sorted(mean_scores, key=lambda x: x[1])\n",
    "    # reverse for descending order (e.g. for accuracy)\n",
    "    if maximize:\n",
    "        mean_scores = list(reversed(mean_scores))\n",
    "    # retrieve the top n for summarization\n",
    "    names = [x[0] for x in mean_scores[:n]]\n",
    "    scores = [results[x[0]] for x in mean_scores[:n]]\n",
    "    # print the top n\n",
    "    print()\n",
    "    for i in range(n):\n",
    "        name = names[i]\n",
    "        mean_score, std_score = mean(results[name]), std(results[name])\n",
    "        print('Rank=%d, Name=%s, Score=%.3f (+/- %.3f)' % (i+1, name, mean_score, std_score))\n",
    "    # boxplot for the top n\n",
    "    pyplot.boxplot(scores, labels=names)\n",
    "    _, labels = pyplot.xticks()\n",
    "    pyplot.setp(labels, rotation=90)\n",
    "    pyplot.savefig('spotcheck.png')\n",
    "    plt.show()\n",
    "\n",
    "##############################################################\n",
    "##############################################################\n",
    "\n",
    "# load dataset\n",
    "X, y = load_dataset()\n",
    "# get model list\n",
    "models = define_models()\n",
    "# evaluate models\n",
    "results = evaluate_models(X, y, models)\n",
    "# summarize results\n",
    "summarize_results(results)\n",
    "\n",
    "##############################################################\n",
    "##############################################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spot-Checking for Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\DS_Softwares\\anaconda3\\envs\\tensorflowcpu\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 190 models\n",
      ">lr: -0.011 (+/-0.001)\n",
      ">lasso-0.0: -0.011 (+/-0.001)\n",
      ">lasso-0.1: -4.756 (+/-0.808)\n",
      ">lasso-0.2: -18.996 (+/-3.268)\n",
      ">lasso-0.3: -42.730 (+/-7.379)\n",
      ">lasso-0.4: -75.957 (+/-13.144)\n",
      ">lasso-0.5: -118.679 (+/-20.561)\n",
      ">lasso-0.6: -170.895 (+/-29.631)\n",
      ">lasso-0.7: -232.605 (+/-40.354)\n",
      ">lasso-0.8: -303.810 (+/-52.729)\n",
      ">lasso-0.9: -384.509 (+/-66.757)\n",
      ">lasso-1.0: -474.701 (+/-82.438)\n",
      ">ridge-0.0: -0.011 (+/-0.001)\n",
      ">ridge-0.1: -0.902 (+/-0.167)\n",
      ">ridge-0.2: -3.534 (+/-0.668)\n",
      ">ridge-0.3: -7.847 (+/-1.492)\n",
      ">ridge-0.4: -13.780 (+/-2.628)\n",
      ">ridge-0.5: -21.277 (+/-4.064)\n",
      ">ridge-0.6: -30.283 (+/-5.788)\n",
      ">ridge-0.7: -40.744 (+/-7.790)\n",
      ">ridge-0.8: -52.610 (+/-10.059)\n",
      ">ridge-0.9: -65.831 (+/-12.586)\n",
      ">ridge-1.0: -80.359 (+/-15.361)\n",
      ">en-0.0-0.0: -0.011 (+/-0.001)\n",
      ">en-0.0-0.1: -0.011 (+/-0.001)\n",
      ">en-0.0-0.2: -0.011 (+/-0.001)\n",
      ">en-0.0-0.3: -0.011 (+/-0.001)\n",
      ">en-0.0-0.4: -0.011 (+/-0.001)\n",
      ">en-0.0-0.5: -0.011 (+/-0.001)\n",
      ">en-0.0-0.6: -0.011 (+/-0.001)\n",
      ">en-0.0-0.7: -0.011 (+/-0.001)\n",
      ">en-0.0-0.8: -0.011 (+/-0.001)\n",
      ">en-0.0-0.9: -0.011 (+/-0.001)\n",
      ">en-0.0-1.0: -0.011 (+/-0.001)\n",
      ">en-0.1-0.0: -19635.111 (+/-3395.451)\n",
      ">en-0.1-0.1: -18906.123 (+/-3275.718)\n",
      ">en-0.1-0.2: -18052.723 (+/-3135.107)\n",
      ">en-0.1-0.3: -17040.802 (+/-2967.784)\n",
      ">en-0.1-0.4: -15822.998 (+/-2765.387)\n",
      ">en-0.1-0.5: -14332.198 (+/-2515.878)\n",
      ">en-0.1-0.6: -12471.327 (+/-2201.595)\n",
      ">en-0.1-0.7: -10100.282 (+/-1796.747)\n",
      ">en-0.1-0.8: -7033.457 (+/-1265.969)\n",
      ">en-0.1-0.9: -3170.692 (+/-580.494)\n",
      ">en-0.1-1.0: -4.756 (+/-0.808)\n",
      ">en-0.2-0.0: -23567.698 (+/-4030.526)\n",
      ">en-0.2-0.1: -23079.263 (+/-3951.314)\n",
      ">en-0.2-0.2: -22490.923 (+/-3855.750)\n",
      ">en-0.2-0.3: -21768.873 (+/-3738.175)\n",
      ">en-0.2-0.4: -20861.672 (+/-3589.976)\n",
      ">en-0.2-0.5: -19687.958 (+/-3396.972)\n",
      ">en-0.2-0.6: -18112.145 (+/-3135.876)\n",
      ">en-0.2-0.7: -15890.529 (+/-2765.333)\n",
      ">en-0.2-0.8: -12547.410 (+/-2202.432)\n",
      ">en-0.2-0.9: -7116.206 (+/-1268.099)\n",
      ">en-0.2-1.0: -18.996 (+/-3.268)\n",
      ">en-0.3-0.0: -25160.296 (+/-4284.521)\n",
      ">en-0.3-0.1: -24800.003 (+/-4226.181)\n",
      ">en-0.3-0.2: -24361.278 (+/-4155.073)\n",
      ">en-0.3-0.3: -23815.315 (+/-4066.424)\n",
      ">en-0.3-0.4: -23117.170 (+/-3952.164)\n",
      ">en-0.3-0.5: -22193.163 (+/-3800.204)\n",
      ">en-0.3-0.6: -20913.503 (+/-3589.444)\n",
      ">en-0.3-0.7: -19024.823 (+/-3277.626)\n",
      ">en-0.3-0.8: -15968.424 (+/-2768.736)\n",
      ">en-0.3-0.9: -10277.647 (+/-1805.660)\n",
      ">en-0.3-1.0: -42.730 (+/-7.379)\n",
      ">en-0.4-0.0: -26021.593 (+/-4421.147)\n",
      ">en-0.4-0.1: -25737.921 (+/-4375.117)\n",
      ">en-0.4-0.2: -25390.543 (+/-4318.739)\n",
      ">en-0.4-0.3: -24955.061 (+/-4247.546)\n",
      ">en-0.4-0.4: -24393.030 (+/-4155.062)\n",
      ">en-0.4-0.5: -23640.200 (+/-4031.347)\n",
      ">en-0.4-0.6: -22578.406 (+/-3857.204)\n",
      ">en-0.4-0.7: -20970.171 (+/-3592.574)\n",
      ">en-0.4-0.8: -18252.335 (+/-3142.595)\n",
      ">en-0.4-0.9: -12738.343 (+/-2216.894)\n",
      ">en-0.4-1.0: -75.957 (+/-13.144)\n",
      ">en-0.5-0.0: -26561.113 (+/-4506.470)\n",
      ">en-0.5-0.1: -26328.065 (+/-4468.524)\n",
      ">en-0.5-0.2: -26041.702 (+/-4421.862)\n",
      ">en-0.5-0.3: -25681.164 (+/-4362.291)\n",
      ">en-0.5-0.4: -25213.433 (+/-4285.171)\n",
      ">en-0.5-0.5: -24581.450 (+/-4181.446)\n",
      ">en-0.5-0.6: -23680.368 (+/-4033.692)\n",
      ">en-0.5-0.7: -22291.911 (+/-3805.502)\n",
      ">en-0.5-0.8: -19878.145 (+/-3407.581)\n",
      ">en-0.5-0.9: -14677.565 (+/-2537.253)\n",
      ">en-0.5-1.0: -118.679 (+/-20.561)\n",
      ">en-0.6-0.0: -26930.765 (+/-4564.815)\n",
      ">en-0.6-0.1: -26733.564 (+/-4532.574)\n",
      ">en-0.6-0.2: -26490.750 (+/-4492.644)\n",
      ">en-0.6-0.3: -26184.271 (+/-4441.692)\n",
      ">en-0.6-0.4: -25785.096 (+/-4375.715)\n",
      ">en-0.6-0.5: -25242.656 (+/-4286.769)\n",
      ">en-0.6-0.6: -24463.135 (+/-4158.770)\n",
      ">en-0.6-0.7: -23248.261 (+/-3959.495)\n",
      ">en-0.6-0.8: -21091.657 (+/-3603.278)\n",
      ">en-0.6-0.9: -16238.518 (+/-2794.559)\n",
      ">en-0.6-1.0: -170.895 (+/-29.631)\n",
      ">en-0.7-0.0: -27199.852 (+/-4607.229)\n",
      ">en-0.7-0.1: -27029.339 (+/-4579.215)\n",
      ">en-0.7-0.2: -26819.155 (+/-4544.278)\n",
      ">en-0.7-0.3: -26553.463 (+/-4499.906)\n",
      ">en-0.7-0.4: -26206.141 (+/-4442.610)\n",
      ">en-0.7-0.5: -25732.412 (+/-4364.561)\n",
      ">en-0.7-0.6: -25048.146 (+/-4252.386)\n",
      ">en-0.7-0.7: -23971.438 (+/-4075.191)\n",
      ">en-0.7-0.8: -22031.580 (+/-3754.765)\n",
      ">en-0.7-0.9: -17519.651 (+/-3005.100)\n",
      ">en-0.7-1.0: -232.605 (+/-40.354)\n",
      ">en-0.8-0.0: -27404.494 (+/-4639.452)\n",
      ">en-0.8-0.1: -27254.624 (+/-4614.698)\n",
      ">en-0.8-0.2: -27069.767 (+/-4583.644)\n",
      ">en-0.8-0.3: -26835.847 (+/-4544.435)\n",
      ">en-0.8-0.4: -26529.250 (+/-4493.791)\n",
      ">en-0.8-0.5: -26109.966 (+/-4424.768)\n",
      ">en-0.8-0.6: -25501.394 (+/-4324.780)\n",
      ">en-0.8-0.7: -24537.682 (+/-4165.742)\n",
      ">en-0.8-0.8: -22781.445 (+/-3875.836)\n",
      ">en-0.8-0.9: -18588.484 (+/-3180.842)\n",
      ">en-0.8-1.0: -303.810 (+/-52.729)\n",
      ">en-0.9-0.0: -27565.366 (+/-4664.763)\n",
      ">en-0.9-0.1: -27431.937 (+/-4642.604)\n",
      ">en-0.9-0.2: -27267.325 (+/-4614.664)\n",
      ">en-0.9-0.3: -27058.767 (+/-4579.707)\n",
      ">en-0.9-0.4: -26784.986 (+/-4534.286)\n",
      ">en-0.9-0.5: -26409.883 (+/-4472.550)\n",
      ">en-0.9-0.6: -25863.151 (+/-4382.199)\n",
      ">en-0.9-0.7: -24993.183 (+/-4238.602)\n",
      ">en-0.9-0.8: -23394.354 (+/-3974.742)\n",
      ">en-0.9-0.9: -19492.825 (+/-3328.396)\n",
      ">en-0.9-1.0: -384.509 (+/-66.757)\n",
      ">en-1.0-0.0: -27695.152 (+/-4685.171)\n",
      ">en-1.0-0.1: -27575.112 (+/-4665.114)\n",
      ">en-1.0-0.2: -27427.092 (+/-4639.759)\n",
      ">en-1.0-0.3: -27239.294 (+/-4608.249)\n",
      ">en-1.0-0.4: -26992.542 (+/-4567.298)\n",
      ">en-1.0-0.5: -26653.630 (+/-4511.312)\n",
      ">en-1.0-0.6: -26158.725 (+/-4429.369)\n",
      ">en-1.0-0.7: -25368.138 (+/-4298.861)\n",
      ">en-1.0-0.8: -23904.654 (+/-4057.544)\n",
      ">en-1.0-0.9: -20267.558 (+/-3454.520)\n",
      ">en-1.0-1.0: -474.701 (+/-82.438)\n",
      ">huber: -0.011 (+/-0.002)\n",
      ">lars: -0.011 (+/-0.001)\n",
      ">llars: -6818.447 (+/-1183.737)\n",
      ">pa: -1119.563 (+/-1093.455)\n",
      ">ranscac: -0.011 (+/-0.001)\n",
      ">sgd: -4367.098 (+/-915.297)\n",
      ">theil: -0.011 (+/-0.002)\n",
      ">knn-1: -30869.042 (+/-3905.159)\n",
      ">knn-2: -23313.703 (+/-4263.314)\n",
      ">knn-3: -21308.250 (+/-3942.296)\n",
      ">knn-4: -19989.521 (+/-3146.635)\n",
      ">knn-5: -19575.096 (+/-3217.275)\n",
      ">knn-6: -19077.575 (+/-2944.185)\n",
      ">knn-7: -18611.225 (+/-3059.335)\n",
      ">knn-8: -18616.046 (+/-2952.398)\n",
      ">knn-9: -18543.176 (+/-2781.085)\n",
      ">knn-10: -18480.473 (+/-2848.115)\n",
      ">knn-11: -18313.496 (+/-2777.947)\n",
      ">knn-12: -18455.572 (+/-2880.450)\n",
      ">knn-13: -18384.412 (+/-3073.738)\n",
      ">knn-14: -18375.317 (+/-2957.064)\n",
      ">knn-15: -18387.072 (+/-3092.035)\n",
      ">knn-16: -18370.580 (+/-3066.935)\n",
      ">knn-17: -18291.717 (+/-3018.298)\n",
      ">knn-18: -18304.525 (+/-2967.820)\n",
      ">knn-19: -18306.125 (+/-3035.414)\n",
      ">knn-20: -18310.841 (+/-3105.589)\n",
      ">cart: -15606.745 (+/-2366.791)\n",
      ">extra: -17451.819 (+/-2539.186)\n",
      ">svml: -23929.372 (+/-4041.658)\n",
      ">svmp: -28939.527 (+/-4869.797)\n",
      ">svmr0.1: -28946.589 (+/-4870.130)\n",
      ">svmr0.2: -28926.546 (+/-4866.800)\n",
      ">svmr0.3: -28906.509 (+/-4863.471)\n",
      ">svmr0.4: -28886.468 (+/-4860.158)\n",
      ">svmr0.5: -28866.440 (+/-4856.849)\n",
      ">svmr0.6: -28846.420 (+/-4853.542)\n",
      ">svmr0.7: -28826.404 (+/-4850.237)\n",
      ">svmr0.8: -28806.395 (+/-4846.933)\n",
      ">svmr0.9: -28786.380 (+/-4843.607)\n",
      ">svmr1.0: -28766.309 (+/-4840.188)\n",
      ">ada: -6050.842 (+/-1497.729)\n",
      ">bag: -6163.819 (+/-1402.976)\n",
      ">rf: -6197.619 (+/-1528.471)\n",
      ">et: -4992.948 (+/-952.072)\n",
      ">gbm: -2346.520 (+/-499.866)\n",
      "\n",
      "Rank=1, Name=lars, Score=-0.011 (+/- 0.001)\n",
      "Rank=2, Name=ridge-0.0, Score=-0.011 (+/- 0.001)\n",
      "Rank=3, Name=ranscac, Score=-0.011 (+/- 0.001)\n",
      "Rank=4, Name=lr, Score=-0.011 (+/- 0.001)\n",
      "Rank=5, Name=en-0.0-1.0, Score=-0.011 (+/- 0.001)\n",
      "Rank=6, Name=en-0.0-0.9, Score=-0.011 (+/- 0.001)\n",
      "Rank=7, Name=en-0.0-0.8, Score=-0.011 (+/- 0.001)\n",
      "Rank=8, Name=en-0.0-0.7, Score=-0.011 (+/- 0.001)\n",
      "Rank=9, Name=en-0.0-0.6, Score=-0.011 (+/- 0.001)\n",
      "Rank=10, Name=en-0.0-0.5, Score=-0.011 (+/- 0.001)\n"
     ]
    }
   ],
   "source": [
    "# regression spot check script\n",
    "import warnings\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from matplotlib import pyplot\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "from sklearn.linear_model import Lars\n",
    "from sklearn.linear_model import LassoLars\n",
    "from sklearn.linear_model import PassiveAggressiveRegressor\n",
    "from sklearn.linear_model import RANSACRegressor\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.linear_model import TheilSenRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import ExtraTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "##############################################################\n",
    "##############################################################\n",
    "\n",
    "# load the dataset, returns X and y elements\n",
    "def load_dataset():\n",
    "    return make_regression(n_samples=1000, n_features=50, noise=0.1, random_state=1)\n",
    "\n",
    "##############################################################\n",
    "##############################################################\n",
    "\n",
    "# create a dict of standard models to evaluate {name:object}\n",
    "def get_models(models=dict()):\n",
    "    \n",
    "    #############################################\n",
    "    \n",
    "    # linear models\n",
    "    models['lr'] = LinearRegression()\n",
    "    \n",
    "    alpha = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "    for a in alpha:\n",
    "        models['lasso-'+str(a)] = Lasso(alpha=a)\n",
    "        \n",
    "    for a in alpha:\n",
    "        models['ridge-'+str(a)] = Ridge(alpha=a)\n",
    "        \n",
    "    for a1 in alpha:\n",
    "        for a2 in alpha:\n",
    "            name = 'en-' + str(a1) + '-' + str(a2)\n",
    "            models[name] = ElasticNet(a1, a2)\n",
    "            \n",
    "    models['huber'] = HuberRegressor()\n",
    "    models['lars'] = Lars()\n",
    "    models['llars'] = LassoLars()\n",
    "    models['pa'] = PassiveAggressiveRegressor(max_iter=1000, tol=1e-3)\n",
    "    models['ranscac'] = RANSACRegressor()\n",
    "    models['sgd'] = SGDRegressor(max_iter=1000, tol=1e-3)\n",
    "    models['theil'] = TheilSenRegressor()\n",
    "    \n",
    "    #############################################\n",
    "    \n",
    "    # non-linear models\n",
    "    n_neighbors = range(1, 21)\n",
    "    for k in n_neighbors:\n",
    "        models['knn-'+str(k)] = KNeighborsRegressor(n_neighbors=k)\n",
    "        \n",
    "    models['cart'] = DecisionTreeRegressor()\n",
    "    models['extra'] = ExtraTreeRegressor()\n",
    "    models['svml'] = SVR(kernel='linear')\n",
    "    models['svmp'] = SVR(kernel='poly')\n",
    "    \n",
    "    c_values = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "    for c in c_values:\n",
    "        models['svmr'+str(c)] = SVR(C=c)\n",
    "        \n",
    "    #############################################\n",
    "    \n",
    "    # ensemble models\n",
    "    n_trees = 100\n",
    "    models['ada'] = AdaBoostRegressor(n_estimators=n_trees)\n",
    "    models['bag'] = BaggingRegressor(n_estimators=n_trees)\n",
    "    models['rf'] = RandomForestRegressor(n_estimators=n_trees)\n",
    "    models['et'] = ExtraTreesRegressor(n_estimators=n_trees)\n",
    "    models['gbm'] = GradientBoostingRegressor(n_estimators=n_trees)\n",
    "    print('Defined %d models' % len(models))\n",
    "    return models\n",
    "\n",
    "##############################################################\n",
    "##############################################################\n",
    "\n",
    "# create a feature preparation pipeline for a model\n",
    "def make_pipeline(model):\n",
    "    steps = list()\n",
    "    # standardization\n",
    "    steps.append(('standardize', StandardScaler()))\n",
    "    # normalization\n",
    "    steps.append(('normalize', MinMaxScaler()))\n",
    "    # the model\n",
    "    steps.append(('model', model))\n",
    "    # create pipeline\n",
    "    pipeline = Pipeline(steps=steps)\n",
    "    return pipeline\n",
    "\n",
    "##############################################################\n",
    "##############################################################\n",
    "\n",
    "# evaluate a single model\n",
    "def evaluate_model(X, y, model, folds, metric):\n",
    "    # create the pipeline\n",
    "    pipeline = make_pipeline(model)\n",
    "    # evaluate model\n",
    "    scores = cross_val_score(pipeline, X, y, scoring=metric, cv=folds, n_jobs=-1)\n",
    "    return scores\n",
    "\n",
    "##############################################################\n",
    "##############################################################\n",
    "\n",
    "# evaluate a model and try to trap errors and and hide warnings\n",
    "def robust_evaluate_model(X, y, model, folds, metric):\n",
    "    scores = None\n",
    "    try:\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings(\"ignore\")\n",
    "            scores = evaluate_model(X, y, model, folds, metric)\n",
    "    except:\n",
    "        scores = None\n",
    "    return scores\n",
    "\n",
    "##############################################################\n",
    "##############################################################\n",
    "\n",
    "# evaluate a dict of models {name:object}, returns {name:score}\n",
    "def evaluate_models(X, y, models, folds=10, metric='accuracy'):\n",
    "    results = dict()\n",
    "    for name, model in models.items():\n",
    "        # evaluate the model\n",
    "        scores = robust_evaluate_model(X, y, model, folds, metric)\n",
    "        # show process\n",
    "        if scores is not None:\n",
    "            # store a result\n",
    "            results[name] = scores\n",
    "            mean_score, std_score = mean(scores), std(scores)\n",
    "            print('>%s: %.3f (+/-%.3f)' % (name, mean_score, std_score))\n",
    "        else:\n",
    "            print('>%s: error' % name)\n",
    "    return results\n",
    "\n",
    "##############################################################\n",
    "##############################################################\n",
    "\n",
    "# print and plot the top n results\n",
    "def summarize_results(results, maximize=True, top_n=10):\n",
    "    # check for no results\n",
    "    if len(results) == 0:\n",
    "        print('no results')\n",
    "        return\n",
    "    # determine how many results to summarize\n",
    "    n = min(top_n, len(results))\n",
    "    # create a list of (name, mean(scores)) tuples\n",
    "    mean_scores = [(k,mean(v)) for k,v in results.items()]\n",
    "    # sort tuples by mean score\n",
    "    mean_scores = sorted(mean_scores, key=lambda x: x[1])\n",
    "    # reverse for descending order (e.g. for accuracy)\n",
    "    if maximize:\n",
    "        mean_scores = list(reversed(mean_scores))\n",
    "    # retrieve the top n for summarization\n",
    "    names = [x[0] for x in mean_scores[:n]]\n",
    "    scores = [results[x[0]] for x in mean_scores[:n]]\n",
    "    # print the top n\n",
    "    print()\n",
    "    for i in range(n):\n",
    "        name = names[i]\n",
    "        mean_score, std_score = mean(results[name]), std(results[name])\n",
    "        print('Rank=%d, Name=%s, Score=%.3f (+/- %.3f)' % (i+1, name, mean_score, std_score))\n",
    "    # boxplot for the top n\n",
    "    pyplot.boxplot(scores, labels=names)\n",
    "    _, labels = pyplot.xticks()\n",
    "    pyplot.setp(labels, rotation=90)\n",
    "    pyplot.savefig('spotcheck_regression.png')\n",
    "\n",
    "##############################################################\n",
    "##############################################################\n",
    "\n",
    "# load dataset\n",
    "X, y = load_dataset()\n",
    "# get model list\n",
    "models = get_models()\n",
    "# evaluate models\n",
    "results = evaluate_models(X, y, models, metric='neg_mean_squared_error')\n",
    "# summarize results\n",
    "summarize_results(results)\n",
    "\n",
    "##############################################################\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Framework Extension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Course Grid Search for Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 53 models\n",
      "Defined 107 models\n",
      ">0logistic: 0.847 (+/-0.037)\n",
      ">1logistic: 0.847 (+/-0.037)\n",
      ">2logistic: 0.846 (+/-0.039)\n",
      ">3logistic: 0.846 (+/-0.039)\n",
      ">0ridge-0.1: 0.846 (+/-0.037)\n",
      ">1ridge-0.1: 0.846 (+/-0.037)\n",
      ">2ridge-0.1: 0.847 (+/-0.037)\n",
      ">3ridge-0.1: 0.847 (+/-0.037)\n",
      ">0ridge-0.2: 0.846 (+/-0.037)\n",
      ">1ridge-0.2: 0.846 (+/-0.037)\n",
      ">2ridge-0.2: 0.847 (+/-0.037)\n",
      ">3ridge-0.2: 0.847 (+/-0.037)\n",
      ">0ridge-0.3: 0.846 (+/-0.037)\n",
      ">1ridge-0.3: 0.846 (+/-0.037)\n",
      ">2ridge-0.3: 0.847 (+/-0.037)\n",
      ">3ridge-0.3: 0.847 (+/-0.037)\n",
      ">0ridge-0.4: 0.846 (+/-0.037)\n",
      ">1ridge-0.4: 0.846 (+/-0.037)\n",
      ">2ridge-0.4: 0.848 (+/-0.038)\n",
      ">3ridge-0.4: 0.848 (+/-0.038)\n",
      ">0ridge-0.5: 0.846 (+/-0.037)\n",
      ">1ridge-0.5: 0.846 (+/-0.037)\n",
      ">2ridge-0.5: 0.848 (+/-0.038)\n",
      ">3ridge-0.5: 0.848 (+/-0.038)\n",
      ">0ridge-0.6: 0.846 (+/-0.037)\n",
      ">1ridge-0.6: 0.846 (+/-0.037)\n",
      ">2ridge-0.6: 0.848 (+/-0.038)\n",
      ">3ridge-0.6: 0.848 (+/-0.038)\n",
      ">0ridge-0.7: 0.846 (+/-0.037)\n",
      ">1ridge-0.7: 0.846 (+/-0.037)\n",
      ">2ridge-0.7: 0.848 (+/-0.038)\n",
      ">3ridge-0.7: 0.848 (+/-0.038)\n",
      ">0ridge-0.8: 0.846 (+/-0.037)\n",
      ">1ridge-0.8: 0.846 (+/-0.037)\n",
      ">2ridge-0.8: 0.848 (+/-0.038)\n",
      ">3ridge-0.8: 0.848 (+/-0.038)\n",
      ">0ridge-0.9: 0.846 (+/-0.037)\n",
      ">1ridge-0.9: 0.846 (+/-0.037)\n",
      ">2ridge-0.9: 0.848 (+/-0.038)\n",
      ">3ridge-0.9: 0.848 (+/-0.038)\n",
      ">0ridge-1.0: 0.846 (+/-0.037)\n",
      ">1ridge-1.0: 0.846 (+/-0.037)\n",
      ">2ridge-1.0: 0.847 (+/-0.038)\n",
      ">3ridge-1.0: 0.847 (+/-0.038)\n",
      ">0sgd: 0.789 (+/-0.054)\n",
      ">1sgd: 0.769 (+/-0.045)\n",
      ">2sgd: 0.803 (+/-0.062)\n",
      ">3sgd: 0.771 (+/-0.072)\n",
      ">0pa: 0.755 (+/-0.049)\n",
      ">1pa: 0.771 (+/-0.056)\n",
      ">2pa: 0.763 (+/-0.088)\n",
      ">3pa: 0.735 (+/-0.109)\n",
      ">0knn-1: 0.733 (+/-0.028)\n",
      ">1knn-1: 0.711 (+/-0.034)\n",
      ">2knn-1: 0.726 (+/-0.042)\n",
      ">3knn-1: 0.726 (+/-0.042)\n",
      ">0knn-2: 0.717 (+/-0.033)\n",
      ">1knn-2: 0.682 (+/-0.022)\n",
      ">2knn-2: 0.688 (+/-0.030)\n",
      ">3knn-2: 0.688 (+/-0.030)\n",
      ">0knn-3: 0.763 (+/-0.033)\n",
      ">1knn-3: 0.722 (+/-0.049)\n",
      ">2knn-3: 0.740 (+/-0.038)\n",
      ">3knn-3: 0.740 (+/-0.038)\n",
      ">0knn-4: 0.766 (+/-0.040)\n",
      ">1knn-4: 0.713 (+/-0.037)\n",
      ">2knn-4: 0.727 (+/-0.027)\n",
      ">3knn-4: 0.727 (+/-0.027)\n",
      ">0knn-5: 0.783 (+/-0.036)\n",
      ">1knn-5: 0.751 (+/-0.028)\n",
      ">2knn-5: 0.767 (+/-0.036)\n",
      ">3knn-5: 0.767 (+/-0.036)\n",
      ">0knn-6: 0.781 (+/-0.023)\n",
      ">1knn-6: 0.748 (+/-0.036)\n",
      ">2knn-6: 0.757 (+/-0.026)\n",
      ">3knn-6: 0.757 (+/-0.026)\n",
      ">0knn-7: 0.792 (+/-0.028)\n",
      ">1knn-7: 0.758 (+/-0.042)\n",
      ">2knn-7: 0.769 (+/-0.037)\n",
      ">3knn-7: 0.769 (+/-0.037)\n",
      ">0knn-8: 0.784 (+/-0.029)\n",
      ">1knn-8: 0.751 (+/-0.046)\n",
      ">2knn-8: 0.762 (+/-0.044)\n",
      ">3knn-8: 0.762 (+/-0.044)\n",
      ">0knn-9: 0.802 (+/-0.040)\n",
      ">1knn-9: 0.760 (+/-0.040)\n",
      ">2knn-9: 0.773 (+/-0.044)\n",
      ">3knn-9: 0.773 (+/-0.044)\n",
      ">0knn-10: 0.792 (+/-0.038)\n",
      ">1knn-10: 0.755 (+/-0.036)\n",
      ">2knn-10: 0.767 (+/-0.042)\n",
      ">3knn-10: 0.767 (+/-0.042)\n",
      ">0knn-11: 0.804 (+/-0.045)\n",
      ">1knn-11: 0.764 (+/-0.034)\n",
      ">2knn-11: 0.783 (+/-0.041)\n",
      ">3knn-11: 0.783 (+/-0.041)\n",
      ">0knn-12: 0.803 (+/-0.034)\n",
      ">1knn-12: 0.762 (+/-0.043)\n",
      ">2knn-12: 0.781 (+/-0.045)\n",
      ">3knn-12: 0.781 (+/-0.045)\n",
      ">0knn-13: 0.821 (+/-0.029)\n",
      ">1knn-13: 0.766 (+/-0.052)\n",
      ">2knn-13: 0.789 (+/-0.041)\n",
      ">3knn-13: 0.789 (+/-0.041)\n",
      ">0knn-14: 0.814 (+/-0.037)\n",
      ">1knn-14: 0.766 (+/-0.054)\n",
      ">2knn-14: 0.787 (+/-0.038)\n",
      ">3knn-14: 0.787 (+/-0.038)\n",
      ">0knn-15: 0.815 (+/-0.046)\n",
      ">1knn-15: 0.785 (+/-0.051)\n",
      ">2knn-15: 0.799 (+/-0.044)\n",
      ">3knn-15: 0.799 (+/-0.044)\n",
      ">0knn-16: 0.809 (+/-0.042)\n",
      ">1knn-16: 0.777 (+/-0.051)\n",
      ">2knn-16: 0.791 (+/-0.039)\n",
      ">3knn-16: 0.791 (+/-0.039)\n",
      ">0knn-17: 0.823 (+/-0.042)\n",
      ">1knn-17: 0.782 (+/-0.047)\n",
      ">2knn-17: 0.799 (+/-0.027)\n",
      ">3knn-17: 0.799 (+/-0.027)\n",
      ">0knn-18: 0.821 (+/-0.045)\n",
      ">1knn-18: 0.777 (+/-0.047)\n",
      ">2knn-18: 0.797 (+/-0.030)\n",
      ">3knn-18: 0.797 (+/-0.030)\n",
      ">0knn-19: 0.825 (+/-0.039)\n",
      ">1knn-19: 0.777 (+/-0.039)\n",
      ">2knn-19: 0.801 (+/-0.031)\n",
      ">3knn-19: 0.801 (+/-0.031)\n",
      ">0knn-20: 0.827 (+/-0.041)\n",
      ">1knn-20: 0.779 (+/-0.038)\n",
      ">2knn-20: 0.802 (+/-0.034)\n",
      ">3knn-20: 0.802 (+/-0.034)\n",
      ">0cart: 0.797 (+/-0.039)\n",
      ">1cart: 0.792 (+/-0.044)\n",
      ">2cart: 0.794 (+/-0.042)\n",
      ">3cart: 0.791 (+/-0.038)\n",
      ">0extra: 0.703 (+/-0.025)\n",
      ">1extra: 0.757 (+/-0.043)\n",
      ">2extra: 0.729 (+/-0.034)\n",
      ">3extra: 0.754 (+/-0.070)\n",
      ">0svml: 0.846 (+/-0.031)\n",
      ">1svml: 0.844 (+/-0.030)\n",
      ">2svml: 0.843 (+/-0.035)\n",
      ">3svml: 0.843 (+/-0.035)\n",
      ">0svmp: 0.828 (+/-0.047)\n",
      ">1svmp: 0.818 (+/-0.047)\n",
      ">2svmp: 0.773 (+/-0.034)\n",
      ">3svmp: 0.773 (+/-0.034)\n",
      ">0svmr0.1: 0.835 (+/-0.036)\n",
      ">1svmr0.1: 0.820 (+/-0.038)\n",
      ">2svmr0.1: 0.797 (+/-0.034)\n",
      ">3svmr0.1: 0.797 (+/-0.034)\n",
      ">0svmr0.2: 0.844 (+/-0.033)\n",
      ">1svmr0.2: 0.830 (+/-0.034)\n",
      ">2svmr0.2: 0.781 (+/-0.043)\n",
      ">3svmr0.2: 0.781 (+/-0.043)\n",
      ">0svmr0.3: 0.841 (+/-0.034)\n",
      ">1svmr0.3: 0.838 (+/-0.031)\n",
      ">2svmr0.3: 0.805 (+/-0.032)\n",
      ">3svmr0.3: 0.805 (+/-0.032)\n",
      ">0svmr0.4: 0.846 (+/-0.036)\n",
      ">1svmr0.4: 0.838 (+/-0.030)\n",
      ">2svmr0.4: 0.817 (+/-0.032)\n",
      ">3svmr0.4: 0.817 (+/-0.032)\n",
      ">0svmr0.5: 0.850 (+/-0.040)\n",
      ">1svmr0.5: 0.842 (+/-0.030)\n",
      ">2svmr0.5: 0.823 (+/-0.029)\n",
      ">3svmr0.5: 0.823 (+/-0.029)\n",
      ">0svmr0.6: 0.852 (+/-0.039)\n",
      ">1svmr0.6: 0.848 (+/-0.031)\n",
      ">2svmr0.6: 0.828 (+/-0.031)\n",
      ">3svmr0.6: 0.828 (+/-0.031)\n",
      ">0svmr0.7: 0.849 (+/-0.040)\n",
      ">1svmr0.7: 0.849 (+/-0.033)\n",
      ">2svmr0.7: 0.833 (+/-0.030)\n",
      ">3svmr0.7: 0.833 (+/-0.030)\n",
      ">0svmr0.8: 0.849 (+/-0.040)\n",
      ">1svmr0.8: 0.849 (+/-0.040)\n",
      ">2svmr0.8: 0.838 (+/-0.033)\n",
      ">3svmr0.8: 0.838 (+/-0.033)\n",
      ">0svmr0.9: 0.848 (+/-0.040)\n",
      ">1svmr0.9: 0.847 (+/-0.037)\n",
      ">2svmr0.9: 0.838 (+/-0.034)\n",
      ">3svmr0.9: 0.838 (+/-0.034)\n",
      ">0svmr1.0: 0.849 (+/-0.040)\n",
      ">1svmr1.0: 0.846 (+/-0.037)\n",
      ">2svmr1.0: 0.837 (+/-0.032)\n",
      ">3svmr1.0: 0.837 (+/-0.032)\n",
      ">0bayes: 0.816 (+/-0.034)\n",
      ">1bayes: 0.816 (+/-0.034)\n",
      ">2bayes: 0.816 (+/-0.034)\n",
      ">3bayes: 0.816 (+/-0.034)\n",
      ">0ada: 0.850 (+/-0.035)\n",
      ">1ada: 0.850 (+/-0.035)\n",
      ">2ada: 0.850 (+/-0.035)\n",
      ">3ada: 0.850 (+/-0.035)\n",
      ">0bag: 0.860 (+/-0.044)\n",
      ">1bag: 0.858 (+/-0.044)\n",
      ">2bag: 0.861 (+/-0.038)\n",
      ">3bag: 0.857 (+/-0.042)\n",
      ">0rf: 0.861 (+/-0.040)\n",
      ">1rf: 0.862 (+/-0.036)\n",
      ">2rf: 0.859 (+/-0.034)\n",
      ">3rf: 0.866 (+/-0.038)\n",
      ">0et: 0.862 (+/-0.038)\n",
      ">1et: 0.859 (+/-0.038)\n",
      ">2et: 0.860 (+/-0.038)\n",
      ">3et: 0.861 (+/-0.034)\n",
      ">0gbm: 0.866 (+/-0.044)\n",
      ">1gbm: 0.865 (+/-0.044)\n",
      ">2gbm: 0.865 (+/-0.044)\n",
      ">3gbm: 0.865 (+/-0.045)\n",
      ">0xgb-[0.001, 50, 0.5, 3]: 0.858 (+/-0.033)\n",
      ">1xgb-[0.001, 50, 0.5, 3]: 0.858 (+/-0.033)\n",
      ">2xgb-[0.001, 50, 0.5, 3]: 0.858 (+/-0.033)\n",
      ">3xgb-[0.001, 50, 0.5, 3]: 0.858 (+/-0.033)\n",
      ">0xgb-[0.001, 50, 0.5, 7]: 0.866 (+/-0.038)\n",
      ">1xgb-[0.001, 50, 0.5, 7]: 0.866 (+/-0.038)\n",
      ">2xgb-[0.001, 50, 0.5, 7]: 0.866 (+/-0.038)\n",
      ">3xgb-[0.001, 50, 0.5, 7]: 0.866 (+/-0.038)\n",
      ">0xgb-[0.001, 50, 0.5, 9]: 0.866 (+/-0.038)\n",
      ">1xgb-[0.001, 50, 0.5, 9]: 0.866 (+/-0.038)\n",
      ">2xgb-[0.001, 50, 0.5, 9]: 0.866 (+/-0.038)\n",
      ">3xgb-[0.001, 50, 0.5, 9]: 0.866 (+/-0.038)\n",
      ">0xgb-[0.001, 50, 0.7, 3]: 0.865 (+/-0.036)\n",
      ">1xgb-[0.001, 50, 0.7, 3]: 0.865 (+/-0.036)\n",
      ">2xgb-[0.001, 50, 0.7, 3]: 0.865 (+/-0.036)\n",
      ">3xgb-[0.001, 50, 0.7, 3]: 0.865 (+/-0.036)\n",
      ">0xgb-[0.001, 50, 0.7, 7]: 0.862 (+/-0.037)\n",
      ">1xgb-[0.001, 50, 0.7, 7]: 0.862 (+/-0.037)\n",
      ">2xgb-[0.001, 50, 0.7, 7]: 0.862 (+/-0.037)\n",
      ">3xgb-[0.001, 50, 0.7, 7]: 0.862 (+/-0.037)\n",
      ">0xgb-[0.001, 50, 0.7, 9]: 0.862 (+/-0.038)\n",
      ">1xgb-[0.001, 50, 0.7, 9]: 0.862 (+/-0.038)\n",
      ">2xgb-[0.001, 50, 0.7, 9]: 0.862 (+/-0.038)\n",
      ">3xgb-[0.001, 50, 0.7, 9]: 0.862 (+/-0.038)\n",
      ">0xgb-[0.001, 50, 1.0, 3]: 0.861 (+/-0.047)\n",
      ">1xgb-[0.001, 50, 1.0, 3]: 0.861 (+/-0.047)\n",
      ">2xgb-[0.001, 50, 1.0, 3]: 0.861 (+/-0.047)\n",
      ">3xgb-[0.001, 50, 1.0, 3]: 0.861 (+/-0.047)\n",
      ">0xgb-[0.001, 50, 1.0, 7]: 0.843 (+/-0.033)\n",
      ">1xgb-[0.001, 50, 1.0, 7]: 0.843 (+/-0.033)\n",
      ">2xgb-[0.001, 50, 1.0, 7]: 0.843 (+/-0.033)\n",
      ">3xgb-[0.001, 50, 1.0, 7]: 0.843 (+/-0.033)\n",
      ">0xgb-[0.001, 50, 1.0, 9]: 0.841 (+/-0.034)\n",
      ">1xgb-[0.001, 50, 1.0, 9]: 0.841 (+/-0.034)\n",
      ">2xgb-[0.001, 50, 1.0, 9]: 0.841 (+/-0.034)\n",
      ">3xgb-[0.001, 50, 1.0, 9]: 0.841 (+/-0.034)\n",
      ">0xgb-[0.001, 100, 0.5, 3]: 0.859 (+/-0.034)\n",
      ">1xgb-[0.001, 100, 0.5, 3]: 0.859 (+/-0.034)\n",
      ">2xgb-[0.001, 100, 0.5, 3]: 0.859 (+/-0.034)\n",
      ">3xgb-[0.001, 100, 0.5, 3]: 0.859 (+/-0.034)\n",
      ">0xgb-[0.001, 100, 0.5, 7]: 0.865 (+/-0.038)\n",
      ">1xgb-[0.001, 100, 0.5, 7]: 0.865 (+/-0.038)\n",
      ">2xgb-[0.001, 100, 0.5, 7]: 0.865 (+/-0.038)\n",
      ">3xgb-[0.001, 100, 0.5, 7]: 0.865 (+/-0.038)\n",
      ">0xgb-[0.001, 100, 0.5, 9]: 0.865 (+/-0.038)\n",
      ">1xgb-[0.001, 100, 0.5, 9]: 0.865 (+/-0.038)\n",
      ">2xgb-[0.001, 100, 0.5, 9]: 0.865 (+/-0.038)\n",
      ">3xgb-[0.001, 100, 0.5, 9]: 0.865 (+/-0.038)\n",
      ">0xgb-[0.001, 100, 0.7, 3]: 0.864 (+/-0.034)\n",
      ">1xgb-[0.001, 100, 0.7, 3]: 0.864 (+/-0.034)\n",
      ">2xgb-[0.001, 100, 0.7, 3]: 0.864 (+/-0.034)\n",
      ">3xgb-[0.001, 100, 0.7, 3]: 0.864 (+/-0.034)\n",
      ">0xgb-[0.001, 100, 0.7, 7]: 0.859 (+/-0.039)\n",
      ">1xgb-[0.001, 100, 0.7, 7]: 0.859 (+/-0.039)\n",
      ">2xgb-[0.001, 100, 0.7, 7]: 0.859 (+/-0.039)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">3xgb-[0.001, 100, 0.7, 7]: 0.859 (+/-0.039)\n",
      ">0xgb-[0.001, 100, 0.7, 9]: 0.860 (+/-0.038)\n",
      ">1xgb-[0.001, 100, 0.7, 9]: 0.860 (+/-0.038)\n",
      ">2xgb-[0.001, 100, 0.7, 9]: 0.860 (+/-0.038)\n",
      ">3xgb-[0.001, 100, 0.7, 9]: 0.860 (+/-0.038)\n",
      ">0xgb-[0.001, 100, 1.0, 3]: 0.860 (+/-0.047)\n",
      ">1xgb-[0.001, 100, 1.0, 3]: 0.860 (+/-0.047)\n",
      ">2xgb-[0.001, 100, 1.0, 3]: 0.860 (+/-0.047)\n",
      ">3xgb-[0.001, 100, 1.0, 3]: 0.860 (+/-0.047)\n",
      ">0xgb-[0.001, 100, 1.0, 7]: 0.847 (+/-0.032)\n",
      ">1xgb-[0.001, 100, 1.0, 7]: 0.847 (+/-0.032)\n",
      ">2xgb-[0.001, 100, 1.0, 7]: 0.847 (+/-0.032)\n",
      ">3xgb-[0.001, 100, 1.0, 7]: 0.847 (+/-0.032)\n",
      ">0xgb-[0.001, 100, 1.0, 9]: 0.845 (+/-0.033)\n",
      ">1xgb-[0.001, 100, 1.0, 9]: 0.845 (+/-0.033)\n",
      ">2xgb-[0.001, 100, 1.0, 9]: 0.845 (+/-0.033)\n",
      ">3xgb-[0.001, 100, 1.0, 9]: 0.845 (+/-0.033)\n",
      ">0xgb-[0.01, 50, 0.5, 3]: 0.860 (+/-0.035)\n",
      ">1xgb-[0.01, 50, 0.5, 3]: 0.860 (+/-0.035)\n",
      ">2xgb-[0.01, 50, 0.5, 3]: 0.860 (+/-0.035)\n",
      ">3xgb-[0.01, 50, 0.5, 3]: 0.860 (+/-0.035)\n",
      ">0xgb-[0.01, 50, 0.5, 7]: 0.863 (+/-0.040)\n",
      ">1xgb-[0.01, 50, 0.5, 7]: 0.863 (+/-0.040)\n",
      ">2xgb-[0.01, 50, 0.5, 7]: 0.863 (+/-0.040)\n",
      ">3xgb-[0.01, 50, 0.5, 7]: 0.863 (+/-0.040)\n",
      ">0xgb-[0.01, 50, 0.5, 9]: 0.863 (+/-0.036)\n",
      ">1xgb-[0.01, 50, 0.5, 9]: 0.863 (+/-0.036)\n",
      ">2xgb-[0.01, 50, 0.5, 9]: 0.863 (+/-0.036)\n",
      ">3xgb-[0.01, 50, 0.5, 9]: 0.863 (+/-0.036)\n",
      ">0xgb-[0.01, 50, 0.7, 3]: 0.865 (+/-0.034)\n",
      ">1xgb-[0.01, 50, 0.7, 3]: 0.865 (+/-0.034)\n",
      ">2xgb-[0.01, 50, 0.7, 3]: 0.865 (+/-0.034)\n",
      ">3xgb-[0.01, 50, 0.7, 3]: 0.865 (+/-0.034)\n",
      ">0xgb-[0.01, 50, 0.7, 7]: 0.862 (+/-0.034)\n",
      ">1xgb-[0.01, 50, 0.7, 7]: 0.862 (+/-0.034)\n",
      ">2xgb-[0.01, 50, 0.7, 7]: 0.862 (+/-0.034)\n",
      ">3xgb-[0.01, 50, 0.7, 7]: 0.862 (+/-0.034)\n",
      ">0xgb-[0.01, 50, 0.7, 9]: 0.862 (+/-0.034)\n",
      ">1xgb-[0.01, 50, 0.7, 9]: 0.862 (+/-0.034)\n",
      ">2xgb-[0.01, 50, 0.7, 9]: 0.862 (+/-0.034)\n",
      ">3xgb-[0.01, 50, 0.7, 9]: 0.862 (+/-0.034)\n",
      ">0xgb-[0.01, 50, 1.0, 3]: 0.867 (+/-0.035)\n",
      ">1xgb-[0.01, 50, 1.0, 3]: 0.867 (+/-0.035)\n",
      ">2xgb-[0.01, 50, 1.0, 3]: 0.867 (+/-0.035)\n",
      ">3xgb-[0.01, 50, 1.0, 3]: 0.867 (+/-0.035)\n",
      ">0xgb-[0.01, 50, 1.0, 7]: 0.863 (+/-0.031)\n",
      ">1xgb-[0.01, 50, 1.0, 7]: 0.863 (+/-0.031)\n",
      ">2xgb-[0.01, 50, 1.0, 7]: 0.863 (+/-0.031)\n",
      ">3xgb-[0.01, 50, 1.0, 7]: 0.863 (+/-0.031)\n",
      ">0xgb-[0.01, 50, 1.0, 9]: 0.857 (+/-0.032)\n",
      ">1xgb-[0.01, 50, 1.0, 9]: 0.857 (+/-0.032)\n",
      ">2xgb-[0.01, 50, 1.0, 9]: 0.857 (+/-0.032)\n",
      ">3xgb-[0.01, 50, 1.0, 9]: 0.857 (+/-0.032)\n",
      ">0xgb-[0.01, 100, 0.5, 3]: 0.864 (+/-0.034)\n",
      ">1xgb-[0.01, 100, 0.5, 3]: 0.864 (+/-0.034)\n",
      ">2xgb-[0.01, 100, 0.5, 3]: 0.864 (+/-0.034)\n",
      ">3xgb-[0.01, 100, 0.5, 3]: 0.864 (+/-0.034)\n",
      ">0xgb-[0.01, 100, 0.5, 7]: 0.860 (+/-0.039)\n",
      ">1xgb-[0.01, 100, 0.5, 7]: 0.860 (+/-0.039)\n",
      ">2xgb-[0.01, 100, 0.5, 7]: 0.860 (+/-0.039)\n",
      ">3xgb-[0.01, 100, 0.5, 7]: 0.860 (+/-0.039)\n",
      ">0xgb-[0.01, 100, 0.5, 9]: 0.860 (+/-0.042)\n",
      ">1xgb-[0.01, 100, 0.5, 9]: 0.860 (+/-0.042)\n",
      ">2xgb-[0.01, 100, 0.5, 9]: 0.860 (+/-0.042)\n",
      ">3xgb-[0.01, 100, 0.5, 9]: 0.860 (+/-0.042)\n",
      ">0xgb-[0.01, 100, 0.7, 3]: 0.866 (+/-0.034)\n",
      ">1xgb-[0.01, 100, 0.7, 3]: 0.866 (+/-0.034)\n",
      ">2xgb-[0.01, 100, 0.7, 3]: 0.866 (+/-0.034)\n",
      ">3xgb-[0.01, 100, 0.7, 3]: 0.866 (+/-0.034)\n",
      ">0xgb-[0.01, 100, 0.7, 7]: 0.864 (+/-0.034)\n",
      ">1xgb-[0.01, 100, 0.7, 7]: 0.864 (+/-0.034)\n",
      ">2xgb-[0.01, 100, 0.7, 7]: 0.864 (+/-0.034)\n",
      ">3xgb-[0.01, 100, 0.7, 7]: 0.864 (+/-0.034)\n",
      ">0xgb-[0.01, 100, 0.7, 9]: 0.863 (+/-0.035)\n",
      ">1xgb-[0.01, 100, 0.7, 9]: 0.863 (+/-0.035)\n",
      ">2xgb-[0.01, 100, 0.7, 9]: 0.863 (+/-0.035)\n",
      ">3xgb-[0.01, 100, 0.7, 9]: 0.863 (+/-0.035)\n",
      ">0xgb-[0.01, 100, 1.0, 3]: 0.866 (+/-0.037)\n",
      ">1xgb-[0.01, 100, 1.0, 3]: 0.866 (+/-0.037)\n",
      ">2xgb-[0.01, 100, 1.0, 3]: 0.866 (+/-0.037)\n",
      ">3xgb-[0.01, 100, 1.0, 3]: 0.866 (+/-0.037)\n",
      ">0xgb-[0.01, 100, 1.0, 7]: 0.861 (+/-0.042)\n",
      ">1xgb-[0.01, 100, 1.0, 7]: 0.861 (+/-0.042)\n",
      ">2xgb-[0.01, 100, 1.0, 7]: 0.861 (+/-0.042)\n",
      ">3xgb-[0.01, 100, 1.0, 7]: 0.861 (+/-0.042)\n",
      ">0xgb-[0.01, 100, 1.0, 9]: 0.859 (+/-0.038)\n",
      ">1xgb-[0.01, 100, 1.0, 9]: 0.859 (+/-0.038)\n",
      ">2xgb-[0.01, 100, 1.0, 9]: 0.859 (+/-0.038)\n",
      ">3xgb-[0.01, 100, 1.0, 9]: 0.859 (+/-0.038)\n",
      ">0xgb-[0.1, 50, 0.5, 3]: 0.863 (+/-0.040)\n",
      ">1xgb-[0.1, 50, 0.5, 3]: 0.863 (+/-0.040)\n",
      ">2xgb-[0.1, 50, 0.5, 3]: 0.863 (+/-0.040)\n",
      ">3xgb-[0.1, 50, 0.5, 3]: 0.863 (+/-0.040)\n",
      ">0xgb-[0.1, 50, 0.5, 7]: 0.852 (+/-0.037)\n",
      ">1xgb-[0.1, 50, 0.5, 7]: 0.852 (+/-0.037)\n",
      ">2xgb-[0.1, 50, 0.5, 7]: 0.852 (+/-0.037)\n",
      ">3xgb-[0.1, 50, 0.5, 7]: 0.852 (+/-0.037)\n",
      ">0xgb-[0.1, 50, 0.5, 9]: 0.860 (+/-0.039)\n",
      ">1xgb-[0.1, 50, 0.5, 9]: 0.860 (+/-0.039)\n",
      ">2xgb-[0.1, 50, 0.5, 9]: 0.860 (+/-0.039)\n",
      ">3xgb-[0.1, 50, 0.5, 9]: 0.860 (+/-0.039)\n",
      ">0xgb-[0.1, 50, 0.7, 3]: 0.864 (+/-0.040)\n",
      ">1xgb-[0.1, 50, 0.7, 3]: 0.864 (+/-0.040)\n",
      ">2xgb-[0.1, 50, 0.7, 3]: 0.864 (+/-0.040)\n",
      ">3xgb-[0.1, 50, 0.7, 3]: 0.864 (+/-0.040)\n",
      ">0xgb-[0.1, 50, 0.7, 7]: 0.863 (+/-0.040)\n",
      ">1xgb-[0.1, 50, 0.7, 7]: 0.863 (+/-0.040)\n",
      ">2xgb-[0.1, 50, 0.7, 7]: 0.863 (+/-0.040)\n",
      ">3xgb-[0.1, 50, 0.7, 7]: 0.863 (+/-0.040)\n",
      ">0xgb-[0.1, 50, 0.7, 9]: 0.860 (+/-0.043)\n",
      ">1xgb-[0.1, 50, 0.7, 9]: 0.860 (+/-0.043)\n",
      ">2xgb-[0.1, 50, 0.7, 9]: 0.860 (+/-0.043)\n",
      ">3xgb-[0.1, 50, 0.7, 9]: 0.860 (+/-0.043)\n",
      ">0xgb-[0.1, 50, 1.0, 3]: 0.872 (+/-0.039)\n",
      ">1xgb-[0.1, 50, 1.0, 3]: 0.872 (+/-0.039)\n",
      ">2xgb-[0.1, 50, 1.0, 3]: 0.872 (+/-0.039)\n",
      ">3xgb-[0.1, 50, 1.0, 3]: 0.872 (+/-0.039)\n",
      ">0xgb-[0.1, 50, 1.0, 7]: 0.867 (+/-0.037)\n",
      ">1xgb-[0.1, 50, 1.0, 7]: 0.867 (+/-0.037)\n",
      ">2xgb-[0.1, 50, 1.0, 7]: 0.867 (+/-0.037)\n",
      ">3xgb-[0.1, 50, 1.0, 7]: 0.867 (+/-0.037)\n",
      ">0xgb-[0.1, 50, 1.0, 9]: 0.868 (+/-0.038)\n",
      ">1xgb-[0.1, 50, 1.0, 9]: 0.868 (+/-0.038)\n",
      ">2xgb-[0.1, 50, 1.0, 9]: 0.868 (+/-0.038)\n",
      ">3xgb-[0.1, 50, 1.0, 9]: 0.868 (+/-0.038)\n",
      ">0xgb-[0.1, 100, 0.5, 3]: 0.855 (+/-0.041)\n",
      ">1xgb-[0.1, 100, 0.5, 3]: 0.855 (+/-0.041)\n",
      ">2xgb-[0.1, 100, 0.5, 3]: 0.855 (+/-0.041)\n",
      ">3xgb-[0.1, 100, 0.5, 3]: 0.855 (+/-0.041)\n",
      ">0xgb-[0.1, 100, 0.5, 7]: 0.850 (+/-0.035)\n",
      ">1xgb-[0.1, 100, 0.5, 7]: 0.850 (+/-0.035)\n",
      ">2xgb-[0.1, 100, 0.5, 7]: 0.850 (+/-0.035)\n",
      ">3xgb-[0.1, 100, 0.5, 7]: 0.850 (+/-0.035)\n",
      ">0xgb-[0.1, 100, 0.5, 9]: 0.854 (+/-0.036)\n",
      ">1xgb-[0.1, 100, 0.5, 9]: 0.854 (+/-0.036)\n",
      ">2xgb-[0.1, 100, 0.5, 9]: 0.854 (+/-0.036)\n",
      ">3xgb-[0.1, 100, 0.5, 9]: 0.854 (+/-0.036)\n",
      ">0xgb-[0.1, 100, 0.7, 3]: 0.862 (+/-0.038)\n",
      ">1xgb-[0.1, 100, 0.7, 3]: 0.862 (+/-0.038)\n",
      ">2xgb-[0.1, 100, 0.7, 3]: 0.862 (+/-0.038)\n",
      ">3xgb-[0.1, 100, 0.7, 3]: 0.862 (+/-0.038)\n",
      ">0xgb-[0.1, 100, 0.7, 7]: 0.861 (+/-0.034)\n",
      ">1xgb-[0.1, 100, 0.7, 7]: 0.861 (+/-0.034)\n",
      ">2xgb-[0.1, 100, 0.7, 7]: 0.861 (+/-0.034)\n",
      ">3xgb-[0.1, 100, 0.7, 7]: 0.861 (+/-0.034)\n",
      ">0xgb-[0.1, 100, 0.7, 9]: 0.858 (+/-0.039)\n",
      ">1xgb-[0.1, 100, 0.7, 9]: 0.858 (+/-0.039)\n",
      ">2xgb-[0.1, 100, 0.7, 9]: 0.858 (+/-0.039)\n",
      ">3xgb-[0.1, 100, 0.7, 9]: 0.858 (+/-0.039)\n",
      ">0xgb-[0.1, 100, 1.0, 3]: 0.864 (+/-0.044)\n",
      ">1xgb-[0.1, 100, 1.0, 3]: 0.864 (+/-0.044)\n",
      ">2xgb-[0.1, 100, 1.0, 3]: 0.864 (+/-0.044)\n",
      ">3xgb-[0.1, 100, 1.0, 3]: 0.864 (+/-0.044)\n",
      ">0xgb-[0.1, 100, 1.0, 7]: 0.865 (+/-0.036)\n",
      ">1xgb-[0.1, 100, 1.0, 7]: 0.865 (+/-0.036)\n",
      ">2xgb-[0.1, 100, 1.0, 7]: 0.865 (+/-0.036)\n",
      ">3xgb-[0.1, 100, 1.0, 7]: 0.865 (+/-0.036)\n",
      ">0xgb-[0.1, 100, 1.0, 9]: 0.867 (+/-0.039)\n",
      ">1xgb-[0.1, 100, 1.0, 9]: 0.867 (+/-0.039)\n",
      ">2xgb-[0.1, 100, 1.0, 9]: 0.867 (+/-0.039)\n",
      ">3xgb-[0.1, 100, 1.0, 9]: 0.867 (+/-0.039)\n",
      "\n",
      "Rank=1, Name=3xgb-[0.1, 50, 1.0, 3], Score=0.872 (+/- 0.039)\n",
      "Rank=2, Name=2xgb-[0.1, 50, 1.0, 3], Score=0.872 (+/- 0.039)\n",
      "Rank=3, Name=1xgb-[0.1, 50, 1.0, 3], Score=0.872 (+/- 0.039)\n",
      "Rank=4, Name=0xgb-[0.1, 50, 1.0, 3], Score=0.872 (+/- 0.039)\n",
      "Rank=5, Name=3xgb-[0.1, 50, 1.0, 9], Score=0.868 (+/- 0.038)\n",
      "Rank=6, Name=2xgb-[0.1, 50, 1.0, 9], Score=0.868 (+/- 0.038)\n",
      "Rank=7, Name=1xgb-[0.1, 50, 1.0, 9], Score=0.868 (+/- 0.038)\n",
      "Rank=8, Name=0xgb-[0.1, 50, 1.0, 9], Score=0.868 (+/- 0.038)\n",
      "Rank=9, Name=3xgb-[0.1, 100, 1.0, 9], Score=0.867 (+/- 0.039)\n",
      "Rank=10, Name=2xgb-[0.1, 100, 1.0, 9], Score=0.867 (+/- 0.039)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#### Classification\n",
    "\n",
    "# binary classification spot check script\n",
    "import warnings\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from matplotlib import pyplot\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "##############################################################\n",
    "##############################################################\n",
    "\n",
    "# load the dataset, returns X and y elements\n",
    "def load_dataset():\n",
    "    return make_classification(n_samples=1000, n_classes=2, random_state=1)\n",
    "\n",
    "##############################################################\n",
    "##############################################################\n",
    "\n",
    "# create a dict of standard models to evaluate {name:object}\n",
    "def define_models(models=dict()):\n",
    "    \n",
    "    ####################################\n",
    "    \n",
    "    # linear models\n",
    "    models['logistic'] = LogisticRegression()\n",
    "    \n",
    "    alpha = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "    for a in alpha:\n",
    "        models['ridge-'+str(a)] = RidgeClassifier(alpha=a)\n",
    "        \n",
    "    models['sgd'] = SGDClassifier(max_iter=1000, tol=1e-3)\n",
    "    models['pa'] = PassiveAggressiveClassifier(max_iter=1000, tol=1e-3)\n",
    "    \n",
    "    ####################################\n",
    "    \n",
    "    # non-linear models\n",
    "    \n",
    "    n_neighbors = range(1, 21)\n",
    "    for k in n_neighbors:\n",
    "        models['knn-'+str(k)] = KNeighborsClassifier(n_neighbors=k)\n",
    "        \n",
    "    models['cart'] = DecisionTreeClassifier()\n",
    "    models['extra'] = ExtraTreeClassifier()\n",
    "    models['svml'] = SVC(kernel='linear')\n",
    "    models['svmp'] = SVC(kernel='poly')\n",
    "    \n",
    "    c_values = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "    for c in c_values:\n",
    "        models['svmr'+str(c)] = SVC(C=c)\n",
    "        \n",
    "    models['bayes'] = GaussianNB()\n",
    "    \n",
    "    ####################################\n",
    "    \n",
    "    # ensemble models\n",
    "    n_trees = 100\n",
    "    models['ada'] = AdaBoostClassifier(n_estimators=n_trees)\n",
    "    models['bag'] = BaggingClassifier(n_estimators=n_trees)\n",
    "    models['rf'] = RandomForestClassifier(n_estimators=n_trees)\n",
    "    models['et'] = ExtraTreesClassifier(n_estimators=n_trees)\n",
    "    models['gbm'] = GradientBoostingClassifier(n_estimators=n_trees)\n",
    "    \n",
    "    ####################################\n",
    "    \n",
    "    print('Defined %d models' % len(models))\n",
    "    return models\n",
    "\n",
    "##############################################################\n",
    "##############################################################\n",
    "\n",
    "# define gradient boosting models\n",
    "def define_gbm_models(models=dict(), use_xgb=True):\n",
    "    # define config ranges\n",
    "    rates = [0.001, 0.01, 0.1]\n",
    "    trees = [50, 100]\n",
    "    ss = [0.5, 0.7, 1.0]\n",
    "    depth = [3, 7, 9]\n",
    "    # add configurations\n",
    "    for l in rates:\n",
    "        for e in trees:\n",
    "            for s in ss:\n",
    "                for d in depth:\n",
    "                    cfg = [l, e, s, d]\n",
    "                    if use_xgb:\n",
    "                        name = 'xgb-' + str(cfg)\n",
    "                        models[name] = XGBClassifier(learning_rate=l, n_estimators=e, subsample=s, max_depth=d)\n",
    "                    else:\n",
    "                        name = 'gbm-' + str(cfg)\n",
    "                        models[name] = GradientBoostingClassifier(learning_rate=l, n_estimators=e, subsample=s, max_depth=d)\n",
    "    print('Defined %d models' % len(models))\n",
    "    return models\n",
    "\n",
    "##############################################################\n",
    "##############################################################\n",
    "\n",
    "# create a feature preparation pipeline for a model\n",
    "def make_pipeline(model):\n",
    "    steps = list()\n",
    "    # standardization\n",
    "    steps.append(('standardize', StandardScaler()))\n",
    "    # normalization\n",
    "    steps.append(('normalize', MinMaxScaler()))\n",
    "    # the model\n",
    "    steps.append(('model', model))\n",
    "    # create pipeline\n",
    "    pipeline = Pipeline(steps=steps)\n",
    "    return pipeline\n",
    "\n",
    "# no transforms pipeline\n",
    "def pipeline_none(model):\n",
    "    return model\n",
    " \n",
    "# standardize transform pipeline\n",
    "def pipeline_standardize(model):\n",
    "    steps = list()\n",
    "    # standardization\n",
    "    steps.append(('standardize', StandardScaler()))\n",
    "    # the model\n",
    "    steps.append(('model', model))\n",
    "    # create pipeline\n",
    "    pipeline = Pipeline(steps=steps)\n",
    "    return pipeline\n",
    " \n",
    "# normalize transform pipeline\n",
    "def pipeline_normalize(model):\n",
    "    steps = list()\n",
    "    # normalization\n",
    "    steps.append(('normalize', MinMaxScaler()))\n",
    "    # the model\n",
    "    steps.append(('model', model))\n",
    "    # create pipeline\n",
    "    pipeline = Pipeline(steps=steps)\n",
    "    return pipeline\n",
    " \n",
    "# standardize and normalize pipeline\n",
    "def pipeline_std_norm(model):\n",
    "    steps = list()\n",
    "    # standardization\n",
    "    steps.append(('standardize', StandardScaler()))\n",
    "    # normalization\n",
    "    steps.append(('normalize', MinMaxScaler()))\n",
    "    # the model\n",
    "    steps.append(('model', model))\n",
    "    # create pipeline\n",
    "    pipeline = Pipeline(steps=steps)\n",
    "    return pipeline\n",
    "\n",
    "##############################################################\n",
    "##############################################################\n",
    "\n",
    "# evaluate a single model\n",
    "def evaluate_model(X, y, model, folds, metric, pipe_func):\n",
    "    # create the pipeline\n",
    "    pipeline = pipe_func(model)\n",
    "    # evaluate model\n",
    "    scores = cross_val_score(pipeline, X, y, scoring=metric, cv=folds, n_jobs=-1)\n",
    "    return scores\n",
    "\n",
    "##############################################################\n",
    "##############################################################\n",
    "\n",
    "# evaluate a model and try to trap errors and and hide warnings\n",
    "def robust_evaluate_model(X, y, model, folds, metric, pipe_func):\n",
    "    scores = None\n",
    "    try:\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings(\"ignore\")\n",
    "            scores = evaluate_model(X, y, model, folds, metric, pipe_func)\n",
    "    except:\n",
    "        scores = None\n",
    "    return scores\n",
    "\n",
    "##############################################################\n",
    "##############################################################\n",
    "\n",
    "# evaluate a dict of models {name:object}, returns {name:score}\n",
    "def evaluate_models(X, y, models, pipe_funcs, folds=10, metric='accuracy'):\n",
    "    results = dict()\n",
    "    for name, model in models.items():\n",
    "        # evaluate model under each preparation function\n",
    "        for i in range(len(pipe_funcs)):\n",
    "            # evaluate the model\n",
    "            scores = robust_evaluate_model(X, y, model, folds, metric, pipe_funcs[i])\n",
    "            # update name\n",
    "            run_name = str(i) + name\n",
    "            # show process\n",
    "            if scores is not None:\n",
    "                # store a result\n",
    "                results[run_name] = scores\n",
    "                mean_score, std_score = mean(scores), std(scores)\n",
    "                print('>%s: %.3f (+/-%.3f)' % (run_name, mean_score, std_score))\n",
    "            else:\n",
    "                print('>%s: error' % run_name)\n",
    "    return results\n",
    "\n",
    "##############################################################\n",
    "##############################################################\n",
    "\n",
    "# print and plot the top n results\n",
    "def summarize_results(results, maximize=True, top_n=10):\n",
    "    # check for no results\n",
    "    if len(results) == 0:\n",
    "        print('no results')\n",
    "        return\n",
    "    # determine how many results to summarize\n",
    "    n = min(top_n, len(results))\n",
    "    # create a list of (name, mean(scores)) tuples\n",
    "    mean_scores = [(k,mean(v)) for k,v in results.items()]\n",
    "    # sort tuples by mean score\n",
    "    mean_scores = sorted(mean_scores, key=lambda x: x[1])\n",
    "    # reverse for descending order (e.g. for accuracy)\n",
    "    if maximize:\n",
    "        mean_scores = list(reversed(mean_scores))\n",
    "    # retrieve the top n for summarization\n",
    "    names = [x[0] for x in mean_scores[:n]]\n",
    "    scores = [results[x[0]] for x in mean_scores[:n]]\n",
    "    # print the top n\n",
    "    print()\n",
    "    for i in range(n):\n",
    "        name = names[i]\n",
    "        mean_score, std_score = mean(results[name]), std(results[name])\n",
    "        print('Rank=%d, Name=%s, Score=%.3f (+/- %.3f)' % (i+1, name, mean_score, std_score))\n",
    "    # boxplot for the top n\n",
    "    pyplot.boxplot(scores, labels=names)\n",
    "    _, labels = pyplot.xticks()\n",
    "    pyplot.setp(labels, rotation=90)\n",
    "    pyplot.savefig('spotcheck_classification_extension.png')\n",
    "\n",
    "##############################################################\n",
    "##############################################################\n",
    "\n",
    "# load dataset\n",
    "X, y = load_dataset()\n",
    "\n",
    "# get model list\n",
    "models = define_models()\n",
    "\n",
    "# add gbm models\n",
    "models = define_gbm_models(models)\n",
    "\n",
    "# define transform pipelines\n",
    "pipelines = [pipeline_none, pipeline_standardize, pipeline_normalize, pipeline_std_norm]\n",
    "\n",
    "# evaluate models\n",
    "results = evaluate_models(X, y, models, pipelines)\n",
    "\n",
    "# summarize results\n",
    "summarize_results(results)\n",
    "\n",
    "##############################################################\n",
    "##############################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflowcpu]",
   "language": "python",
   "name": "conda-env-tensorflowcpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
